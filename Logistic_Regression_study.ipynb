{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# pip install patsy\n",
    "from patsy import dmatrices, dmatrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- survival:        Survival\n",
    "                (0 = No; 1 = Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Weisz, Mrs. Leopold (Mathilde Francoise Pede)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228414</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>799</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ibrahim Shawah, Mr. Yousseff</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2685</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          883         0       3   \n",
       "1          134         1       2   \n",
       "2          877         0       3   \n",
       "3          799         0       3   \n",
       "4          871         0       3   \n",
       "\n",
       "                                            Name     Sex   Age  SibSp  Parch  \\\n",
       "0                   Dahlberg, Miss. Gerda Ulrika  female  22.0      0      0   \n",
       "1  Weisz, Mrs. Leopold (Mathilde Francoise Pede)  female  29.0      1      0   \n",
       "2                  Gustafsson, Mr. Alfred Ossian    male  20.0      0      0   \n",
       "3                   Ibrahim Shawah, Mr. Yousseff    male  30.0      0      0   \n",
       "4                              Balkic, Mr. Cerin    male  26.0      0      0   \n",
       "\n",
       "   Ticket     Fare Embarked  \n",
       "0    7552  10.5167        S  \n",
       "1  228414  26.0000        S  \n",
       "2    7534   9.8458        S  \n",
       "3    2685   7.2292        C  \n",
       "4  349248   7.8958        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = dmatrices('Survived ~ Age + C(Pclass) + C(Sex)', train, return_type='dataframe')\n",
    "#y & X are DataFrames now with one-hot enocoding/dummy encoding\n",
    "\n",
    "# flatten y so we can incorporate in sklearn functions\n",
    "y = np.ravel(y)\n",
    "#y is now an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>C(Pclass)[T.2]</th>\n",
       "      <th>C(Pclass)[T.3]</th>\n",
       "      <th>C(Sex)[T.male]</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  C(Pclass)[T.2]  C(Pclass)[T.3]  C(Sex)[T.male]   Age\n",
       "0        1.0             0.0             1.0             0.0  22.0\n",
       "1        1.0             1.0             0.0             0.0  29.0\n",
       "2        1.0             0.0             1.0             1.0  20.0\n",
       "3        1.0             0.0             1.0             1.0  30.0\n",
       "4        1.0             0.0             1.0             1.0  26.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize the features since regularization requires all features to be on same scale\n",
    "scaler = StandardScaler(copy=True)\n",
    "# we have created a standardization based on the training data\n",
    "X_clean = scaler.fit(X).transform(X)\n",
    "#X_clean is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_clean2 = pd.DataFrame(X_clean, columns=X.columns)\n",
    "#X_clean2 is a DataFrame of standardized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>C(Pclass)[T.2]</th>\n",
       "      <th>C(Pclass)[T.3]</th>\n",
       "      <th>C(Sex)[T.male]</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>-1.334733</td>\n",
       "      <td>-0.526716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.816233</td>\n",
       "      <td>-1.012159</td>\n",
       "      <td>-1.334733</td>\n",
       "      <td>-0.045169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.749213</td>\n",
       "      <td>-0.664301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.749213</td>\n",
       "      <td>0.023623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.749213</td>\n",
       "      <td>-0.251546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  C(Pclass)[T.2]  C(Pclass)[T.3]  C(Sex)[T.male]       Age\n",
       "0        0.0       -0.550590        0.987988       -1.334733 -0.526716\n",
       "1        0.0        1.816233       -1.012159       -1.334733 -0.045169\n",
       "2        0.0       -0.550590        0.987988        0.749213 -0.664301\n",
       "3        0.0       -0.550590        0.987988        0.749213  0.023623\n",
       "4        0.0       -0.550590        0.987988        0.749213 -0.251546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clean2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c524fa3780>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFhCAYAAAAP07LiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAgAAIBICAAAgKT/D32Ht9+myjv+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c5253f8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparing coeff of not-standarized data with standardized data.\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "#https://stackoverflow.com/questions/33049884/how-to-plot-2-seaborn-lmplots-side-by-side\n",
    "sns.regplot(x='C(Pclass)[T.3]', y='C(Sex)[T.male]', data=X, ci=None, ax=ax1)\n",
    "sns.regplot(x='C(Pclass)[T.3]', y='C(Sex)[T.male]', data=x_clean2, ci=None, ax = ax2)\n",
    "#sns.lmplot(x='C(Pclass)[T.3]', y='C(Sex)[T.male]', data=X, ci=None)\n",
    "#sns.lmplot(x='C(Pclass)[T.3]', y='C(Sex)[T.male]', data=x_clean2, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##correlations dataframe and pair plots\n",
    "#x_clean2.corr()\n",
    "####scatter plots #http://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "#sns.pairplot(x_clean2)\n",
    "\n",
    "### corrfunc (due to peason)only works with continuous data\n",
    "###https://stackoverflow.com/questions/30942577/seaborn-correlation-coefficient-on-pairgrid\n",
    "# def corrfunc(x, y, **kws):\n",
    "#     r, _ = stats.pearsonr(x, y)\n",
    "#     ax = plt.gca()\n",
    "#     ax.annotate(\"r = {:.2f}\".format(r),\n",
    "#                 xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "# g = sns.PairGrid(x_clean2, palette=[\"red\"])\n",
    "# g.map_upper(plt.scatter, s=10)\n",
    "# g.map_diag(sns.distplot, kde=False)\n",
    "# g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "# g.map_lower(corrfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.5009946  -1.29828165 -1.17899065 -0.56802213]]\n"
     ]
    }
   ],
   "source": [
    "# build our initial model with Regularization\n",
    "\n",
    "#### Regularization ####\n",
    "#L1 LASSO (absoute sum of errors) weak coef goes to zero\n",
    "#L2 RIDGE (squared sum of errors)\n",
    "lr = LogisticRegression('l1')\n",
    "lr.fit(X_clean, y)\n",
    "print (lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.85      0.84       397\n",
      "        1.0       0.76      0.73      0.75       265\n",
      "\n",
      "avg / total       0.80      0.80      0.80       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score ,accuracy_score,confusion_matrix,classification_report,log_loss\n",
    "print(classification_report(y, lr.predict(x_clean2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [[337  60]\n",
      " [ 72 193]] \n",
      "\n",
      " or \n",
      "\n",
      " col_0  0.0  1.0\n",
      "row_0          \n",
      "0.0    337   72\n",
      "1.0     60  193 \n",
      "\n",
      " or\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>337</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>60</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual  0.0  1.0\n",
       "Pred            \n",
       "0.0     337   72\n",
       "1.0      60  193"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\",confusion_matrix(y, lr.predict(x_clean2)),\"\\n\\n or \\n\\n\"\n",
    "#pandas crosstab accepts Arrays\n",
    ",pd.crosstab(lr.predict(x_clean2),y),\"\\n\\n or\")\n",
    "\n",
    "fin2 = pd.DataFrame([lr.predict(x_clean2),y], index=['Pred','Actual']).T\n",
    "\n",
    "pd.crosstab(fin2['Pred'],fin2['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800604229607 \n",
      " Accuracy: 0.800604229607 \n",
      " Precision: 0.762845849802 \n",
      " Recall/Sensitivity: 0.728301886792 \n",
      " Specificity: 0.848866498741 \n",
      " F1-Score: 0.745173745174\n"
     ]
    }
   ],
   "source": [
    "#https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "#https://www.quora.com/What-is-the-best-way-to-understand-the-terms-precision-and-recall\n",
    "print('Accuracy:',(lr.predict(x_clean2)==y).mean(),'\\n', #Accuracy\n",
    "      'Accuracy:',accuracy_score(y, lr.predict(x_clean2)),'\\n' #Accuracy\n",
    ",'Precision:',((lr.predict(x_clean2)==y)&(y==1)).sum()/(lr.predict(x_clean2)).sum(),'\\n'\n",
    "# Precision\n",
    ",'Recall/Sensitivity:',((lr.predict(x_clean2)==y)&(y==1)).sum()/(y[y==1]).sum(),'\\n'\n",
    "#Recall or Sensitivity\n",
    ",'Specificity:',((lr.predict(x_clean2)==y)&(y==0)).sum() /len(y[y==0]),'\\n'\n",
    "#Specificity or True negative/ConditionNegative or Negative Recall\n",
    ",'F1-Score:',(2*( (((lr.predict(x_clean2)==y)&(y==1)).sum()/(y[y==1]).sum())\\\n",
    "      *(((lr.predict(x_clean2)==y)&(y==1)).sum()/(lr.predict(x_clean2)).sum())))/\\\n",
    "      ( (((lr.predict(x_clean2)==y)&(y==1)).sum()/(y[y==1]).sum())\\\n",
    "      +(((lr.predict(x_clean2)==y)&(y==1)).sum()/(lr.predict(x_clean2)).sum())))\n",
    "#F1-Score (2*Precision*Recall)/(Precision+Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04991728,  0.95008272]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sparse girl\n",
    "girl = [1., 0., 0., 0., 21.]\n",
    "girl = scaler.fit(X).transform(girl)\n",
    "lr.predict_proba(girl.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.55059023 -1.0121585  -1.33473316 -0.59550826]\n"
     ]
    }
   ],
   "source": [
    "print(girl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.55562741])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.5009946 , -1.29828165, -1.17899065, -0.56802213])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Manually Calculate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log odds are ...[ 2.94598056]\n",
      "Odds of survival are ...[ 19.02931255]\n",
      "Probablity of survival is ....[ 0.95007317]\n"
     ]
    }
   ],
   "source": [
    "#Add intercept + coefficients*StandardizedValues = Logodds of New values\n",
    "logodds = lr.intercept_ +(-0.50089255* -0.55059023)+(-1.2981623*-1.0121585)+(-1.1789864*-1.33473316)+\\\n",
    "(-0.56799074* -0.59550826)\n",
    "print('Log odds are ...'+str(logodds))\n",
    "\n",
    "#Convert log-odds to jusst odds\n",
    "odds = np.exp(logodds)\n",
    "print('Odds of survival are ...'+str(odds))\n",
    "#Pass through sigmoid function or pass through link function to get Probability\n",
    "prob = odds/(1 + odds)\n",
    "print('Probablity of survival is ....'+str(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Use a function to Calculate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.e**(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of survival is ...[ 0.95008272]\n"
     ]
    }
   ],
   "source": [
    "print('Probablity of survival is ...'+str(sigmoid( np.dot(girl, lr.coef_.T) + lr.intercept_ )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Use sklearn predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of survival is ...[ 0.95008272]\n"
     ]
    }
   ],
   "source": [
    "# compute predicted probability for al=2 using the predict_proba method\n",
    "print('Probablity of survival is ...'+str(lr.predict_proba(girl.reshape(1,-1))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit without a bias term (intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C(Pclass)[T.2]</th>\n",
       "      <th>C(Pclass)[T.3]</th>\n",
       "      <th>C(Sex)[T.male]</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C(Pclass)[T.2]  C(Pclass)[T.3]  C(Sex)[T.male]   Age\n",
       "0             0.0             1.0             0.0  22.0\n",
       "1             1.0             0.0             0.0  29.0\n",
       "2             0.0             1.0             1.0  20.0\n",
       "3             0.0             1.0             1.0  30.0\n",
       "4             0.0             1.0             1.0  26.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Used X Dataframe of raw data (Not Standardized Only Dummy/One-Hot encoded)\n",
    "XX = X.copy()\n",
    "del XX['Intercept']\n",
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>-1.334733</td>\n",
       "      <td>-0.526716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.816233</td>\n",
       "      <td>-1.012159</td>\n",
       "      <td>-1.334733</td>\n",
       "      <td>-0.045169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.749213</td>\n",
       "      <td>-0.664301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.749213</td>\n",
       "      <td>0.023623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.550590</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.749213</td>\n",
       "      <td>-0.251546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.550590  0.987988 -1.334733 -0.526716\n",
       "1  1.816233 -1.012159 -1.334733 -0.045169\n",
       "2 -0.550590  0.987988  0.749213 -0.664301\n",
       "3 -0.550590  0.987988  0.749213  0.023623\n",
       "4 -0.550590  0.987988  0.749213 -0.251546"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize the features since regularization requires all features to be on same scale\n",
    "scaler = StandardScaler(copy=True)\n",
    "# we have created a standardization based on the training data\n",
    "XX = scaler.fit(XX).transform(XX)\n",
    "#XX is now an Array\n",
    "pd.DataFrame(XX).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51302494 -1.24581795 -1.18689471 -0.5391433 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# build our initial model\n",
    "# sklearn by default fits an intercept\n",
    "# set fit_intercept = False\n",
    "\n",
    "#L1 LASSO Regularization (append sum of absolute error) weak coeff drop to 0.\n",
    "lr1 = LogisticRegression('l1',fit_intercept=False)\n",
    "# fit method also accepts DataFrames\n",
    "lr1.fit(pd.DataFrame(XX),pd.DataFrame(y) )\n",
    "print (lr1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        , -0.5009946 , -1.29828165, -1.17899065, -0.56802213]),\n",
       " 'coef of previous model (with intercept) vs new model (without intercept)',\n",
       " array([[-0.51302494, -1.24581795, -1.18689471, -0.5391433 ]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[0],\\\n",
    "'coef of previous model (with intercept) vs new model (without intercept)',lr1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fin = pd.DataFrame([lr1.predict(XX),y], index=['Pred','Actual']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>302</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>95</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual  0.0  1.0\n",
       "Pred            \n",
       "0.0     302   51\n",
       "1.0      95  214"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(fin['Pred'],fin['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77945619335347427"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lr1.predict(XX)==y).mean() ##accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96919186])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction of girl\n",
    "sigmoid( np.dot(girl[1:], lr1.coef_.T) + lr1.intercept_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CostFunction & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ignoring the regularization, the cost function for logistic regression is logloss\n",
    "#logloss is similar to cross entropy and maximum likelihood\n",
    "\n",
    "#below we manually compute logloss and manually optimize for best coeff (betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Give a beta0 and betoa1 -0.9, 0.1\n",
    "#b0=-0.99\n",
    "#b1=0.14\n",
    "b0 = 0.37296654876\n",
    "b1 = 0.60609744787\n",
    "\n",
    "b0 = -0.92\n",
    "b1 = 0.75\n",
    "b0 = -0.780931128764\n",
    "b1 = 0.889068871236\n",
    "\n",
    "#b0=-0.89679838  \n",
    "#b1=0.1487704\n",
    "\n",
    "\n",
    "rawdata = [21,2,5,31,10,0.34,.23]#Actual Variables x1 only 1 variable in this example\n",
    "test_P=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate Probability through the logit function\n",
    "for data in rawdata:\n",
    "    P = (np.exp(1)**(b0+b1*data))/(1+np.exp(1)**(b0+b1*data))\n",
    "    test_P.append(P)#suggested probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.75317668511692704, 0.24682331488307296),\n",
       " (0.14216970690529057, 0.85783029309470948),\n",
       " (0.20793209371899476, 0.79206790628100521),\n",
       " (0.93393645064285191, 0.066063549357148088),\n",
       " (0.36103990907589123, 0.63896009092410877),\n",
       " (0.11386153906500995, 0.88613846093499005),\n",
       " (0.1121709785080149, 0.88782902149198506)]"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (P,1-P) for P in test_P] #Predictions. Predict probability of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logloss is ... 1.42603090753\n",
      "The Logloss is ... -0.524670331988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4260309075281967"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Calculate Cost function Given Predictions\n",
    "####  which is probability of 1 Given b0,b1 entered above ##########\n",
    "\n",
    "##Calculate log losss then minimize\n",
    "target_list=[1,0,0,1,0,0,0] #the target given the variables from rawdata\n",
    "fin=[]\n",
    "nz = .000000000000001\n",
    "for target,PredictionProbability in zip(target_list,test_P):\n",
    "    fin.append((target*np.log(PredictionProbability+nz) + (1-target)*np.log(1-PredictionProbability+nz)))\n",
    "print('The Logloss is ... '+str(-1*sum(fin))) #LogLoss\n",
    "print('The Logloss is ... '+str(-1*sum(fin)+(b0+b1))) #LogLoss but with L1 regularization?\n",
    "#http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/\n",
    "log_loss(target_list,test_P,normalize=False)\n",
    "#2.9245329377547962\n",
    "#2.7279212507689738.....b0=-0.9,b1 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative logloss is...-0.0957135012129 -0.0136733573161\n"
     ]
    }
   ],
   "source": [
    "#derivative of log loss\n",
    "#Give a beta0 and betoa1\n",
    "\n",
    "deriv_finX1=[]\n",
    "deriv_finX0=[]\n",
    "b0=b0\n",
    "b1=b1\n",
    "for act,data in zip(target_list,rawdata):\n",
    "    deriv_finX1.append(((act*b1)/(1+np.exp(1)**(b0+b1*data))) - ((b1*np.exp(1)**(b0+b1*data)-act*b1*np.exp(1)**(b0+b1*data))/\\\n",
    "                                                        (1+np.exp(1)**(b0+b1*data))))\n",
    "print('derivative logloss is...'+str(sum(deriv_finX1)),sum(deriv_finX1)/len(rawdata))# <- for mean logloss is actual logloss a mean?\n",
    "#http://www.exegetic.biz/blog/2015/12/making-sense-logarithmic-loss/\n",
    "#log_loss(target,PredictionProbability,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 0.753176685117  *  21  =  5.18328961254\n",
      "0 - 0.142169706905  *  2  =  -0.284339413811\n",
      "0 - 0.207932093719  *  5  =  -1.03966046859\n",
      "1 - 0.933936450643  *  31  =  2.04797003007\n",
      "0 - 0.361039909076  *  10  =  -3.61039909076\n",
      "0 - 0.113861539065  *  0.34  =  -0.0387129232821\n",
      "0 - 0.112170978508  *  0.23  =  -0.0257993250568\n",
      "-0.0891839090047 -0.624287363033 0.318906917302 2.23234842111\n"
     ]
    }
   ],
   "source": [
    "#new derivative\n",
    "#https://math.stackexchange.com/questions/477207/derivative-of-cost-function-for-logistic-regression\n",
    "intercept = [1]*len(rawdata)\n",
    "#for act,data in zip(target_list,rawdata,intercept):\n",
    "dev0 = []\n",
    "dev1 = []\n",
    "for act,p,data,ones in zip(target_list,test_P,rawdata,intercept):\n",
    "    dev0.append((act-p)*ones)\n",
    "    dev1.append((act-p)*data)\n",
    "    print(act,'-',p,' * ',data,' = ',(act-p)*data)\n",
    "print(sum(dev0)/len(rawdata),sum(dev0),sum(dev1)/len(rawdata),sum(dev1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = -2.11293604667\n",
      "b1 = 0.185207107984\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha =0.1\n",
    "# print('b0 =',b0-alpha*(sum(deriv_fin)+(b0+b1)))#,sum(new_b0))\n",
    "# print('b1 =',b1-alpha*(sum(deriv_finX1)+(b0+b1)))\n",
    "print('b0 =',b0+alpha*(sum(dev0)/(len(rawdata) )))#,sum(new_b0))\n",
    "print('b1 =',b1+alpha*(sum(dev1)/(len(rawdata) )))\n",
    "print('\\n')\n",
    "#why divide derivative by number of number of rows???? and \n",
    "#switched update to plus(+)? thought we wanted (-) always\n",
    "#how do I add L1 or L2 regularizer?? 1/#of rows + sum(betas)??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.10401765577, 0.153316416254)"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0 , b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update statement not sure which update statement ?? \n",
    "#http://iamtrask.github.io/2015/07/27/python-network-part2/\n",
    "#http://machinelearningmastery.com/logistic-regression-tutorial-for-machine-learning/\n",
    "#http://www.exegetic.biz/blog/2015/12/making-sense-logarithmic-loss/\n",
    "#http://www.cbcb.umd.edu/~hcorrada/PML/homeworks/HW04_solutions.pdf\n",
    "#http://www.robots.ox.ac.uk/~az/lectures/ml/2011/lect4.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.89679838  0.1487704 ]]\n"
     ]
    }
   ],
   "source": [
    "#### Optimizer of Costfunction Given :b01,b1, derivative of logloss and learning rate ######\n",
    "\n",
    "#b0=b0+alpha*(y-prediction)*prediction*(1-prediction)*x0\n",
    "#b1=b1+alpha*(y-prediction)*prediction*(1-prediction)*x1\n",
    "\n",
    "#ANSWER KEY WHAT coeff should be\n",
    "exampl = pd.DataFrame.from_dict({'x':rawdata,'y':target_list})\n",
    "y4, X4 = dmatrices('y ~ x', exampl, return_type='dataframe')\n",
    "# flatten y so we can incorporate in sklearn functions\n",
    "y4 = np.ravel(y4)\n",
    "lr1 = LogisticRegression(max_iter=1000,fit_intercept=True)\n",
    "lr1.fit(X4,y4 )\n",
    "print (lr1.coef_)\n",
    "#try other cofficients to see if you can do better sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = -2.12119481118\n",
      "b1 = 0.135185211981\n",
      "\n",
      " Slope is negative go forward\n"
     ]
    }
   ],
   "source": [
    "##Probably dont need this\n",
    "#alpha =0.3\n",
    "#b0=\n",
    "#x0=1\n",
    "# new_b0=[]\n",
    "# new_b1=[]\n",
    "# for target,data,PredictionProbability in zip(target_list,rawdata,test_P):\n",
    "#     #new_b0.append(alpha*(target-PredictionProbability)*PredictionProbability*(1-PredictionProbability)*x0)\n",
    "#     new_b0.append(alpha*(b1*((target-1)*(np.exp(1)**(b0+b1*data))+target)/(np.exp(1)**(b0+b1*data)+1)))\n",
    "# #b1=\n",
    "#     #new_b1.append(alpha*(target-PredictionProbability)*PredictionProbability*(1-PredictionProbability)*data)\n",
    "#     new_b1.append(alpha*(b1*((target-1)*(np.exp(1)**(b0+b1*data))+target)/(np.exp(1)**(b0+b1*data)+1)))\n",
    "# if abs(sum(deriv_fin))<=0.0001:\n",
    "#     print('should\\'ve stopped betas good!\\n')\n",
    "# elif sum(deriv_fin)<0:\n",
    "#     print('b0 =',b0+sum(new_b0))#,sum(new_b0))\n",
    "#     print('b1 =',b1+sum(new_b1))#,sum(new_b1))\n",
    "#     print('\\n Slope is negative go forward')\n",
    "# elif sum(deriv_fin)>0:\n",
    "#     print('b0 =',b0-sum(new_b0))#,sum(new_b0))\n",
    "#     print('b1 =',b1-sum(new_b1))#,sum(new_b1))\n",
    "#     print('\\n Slope is positive go backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newD = pd.DataFrame(rawdata,columns=['X1'])\n",
    "newD['intercept']=intercept\n",
    "newD['target_list'] = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>intercept</th>\n",
       "      <th>target_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X1  intercept  target_list\n",
       "0  21.00          1            1\n",
       "1   2.00          1            0\n",
       "2   5.00          1            0\n",
       "3  31.00          1            1\n",
       "4  10.00          1            0\n",
       "5   0.34          1            0\n",
       "6   0.23          1            0"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bet0= 0\n",
    "bet1= 0\n",
    "\n",
    "beta0,beta1,logloss,accuracy,derivativeX0 =[],[],[],[],[]\n",
    "derivativeX1,loglossM,derivativeX0M,derivativeX1M =[],[],[],[]\n",
    "\n",
    "for it in range(1000):\n",
    "#MODEL output is Probability of 1\n",
    "    beta0.append(bet0)\n",
    "    beta1.append(bet1)\n",
    "    \n",
    "    test_P=[]\n",
    "    for data in newD['X1']:\n",
    "        P = (np.exp(1)**(bet0+bet1*data))/(1+np.exp(1)**(bet0+bet1*data))\n",
    "        test_P.append(P)\n",
    "    fin=[]\n",
    "    nz = .000000000000001\n",
    "\n",
    "    #COST/LOSS FUNCTION #helps compare outcome vs other versions of model\n",
    "    for target,PredictionProbability in zip(newD['target_list'],test_P):\n",
    "        fin.append((target*np.log(PredictionProbability+nz) + (1-target)*np.log(1-PredictionProbability+nz)))\n",
    "    #print('The Logloss is ... '+str(-1*sum(fin))) #LogLoss\n",
    "    #print('The Logloss is ... '+str(-1*sum(fin)+(b0+b1)))\n",
    "    logloss.append(-1*sum(fin))\n",
    "    loglossM.append(-1*sum(fin)/len(rawdata))\n",
    "\n",
    "    #DERIVATIVE\n",
    "    dev0 = []\n",
    "    dev1 = []\n",
    "    for act,p,data,ones in zip(newD['target_list'],test_P,newD['X1'],newD['intercept']):\n",
    "        dev0.append((act-p)*ones)\n",
    "        dev1.append((act-p)*data)\n",
    "        #print(act,'-',p,' * ',data,' = ',(act-p)*data)\n",
    "    #print(sum(dev0)/len(rawdata),sum(dev0),sum(dev1)/len(rawdata),sum(dev1))\n",
    "    derivativeX0.append(sum(dev0))\n",
    "    derivativeX0M.append(sum(dev0)/len(rawdata))\n",
    "    derivativeX1.append(sum(dev1))\n",
    "    derivativeX1M.append(sum(dev1)/len(rawdata))\n",
    "    \n",
    "    \n",
    "    #UPDATE\n",
    "    alpha =1/(10)#+((bet0)**2+(bet1)**2))#0.1\n",
    "    # print('b0 =',b0-alpha*(sum(deriv_fin)+(b0+b1)))#,sum(new_b0))\n",
    "    # print('b1 =',b1-alpha*(sum(deriv_finX1)+(b0+b1)))\n",
    "    #print('b0 =',bet0+alpha*(sum(dev0)/(len(newD['X1']) )))#,sum(new_b0))\n",
    "    #print('b1 =',bet1+alpha*(sum(dev1)/(len(newD['X1']) )))\n",
    "    #print('\\n')\n",
    "    \n",
    "    accu = [ 1 if x==i else 0 for (x,i) in zip([ 1 if v>.5 else 0 for v in test_P ],target_list)]\n",
    "    accuracy.append(sum(accu)/len(accu))\n",
    "    \n",
    "    \n",
    "    bet0 = bet0+alpha*(sum(dev0)/(len(rawdata) ))\n",
    "    bet1 = bet1+alpha*(sum(dev1)/(len(rawdata) ))\n",
    "\n",
    "#enter it results in dataframe\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end = pd.DataFrame({'beta0':beta0 ,\n",
    "'beta1':beta1 ,\n",
    "'logloss':logloss, \n",
    "'accuracy':accuracy ,\n",
    "'derivativeX0':derivativeX0, \n",
    "'derivativeX1':derivativeX1 ,\n",
    "'loglossM':loglossM ,\n",
    "'derivativeX0M':derivativeX0M, \n",
    "'derivativeX1M':derivativeX1M})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end.to_csv('logistic_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.2349469673588249, 0.29893137282938093)"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bet0, bet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89679838,  0.1487704 ]])"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12196542747395382"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-2.10401765577)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.6890277199809391"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bet0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l2'"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.penalty"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
