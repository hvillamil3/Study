{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "from pymc3 import Normal, Binomial, sample, Model # Import relevant distributions\n",
    "from pymc3.math import invlogit\n",
    "# Use a theano shared variable to be able to exchange the data the model runs on\n",
    "from theano import shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hvill\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Data (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TOY DATA LOGISTIC Regression\n",
    "#> set.seed(666)\n",
    "np.random.seed(seed=233423)\n",
    "x1 = st.norm.rvs(size=10000)           # some continuous variables \n",
    "x2 = st.norm.rvs(size=10000)  \n",
    "z = 1 + 2 *x1 +3 *x2        # linear combination with a bias\n",
    "pr = 1/(1 +np.exp(-z))         # pass through an inv-logit function\n",
    "y = st.binom.rvs(n=1,p=pr, size=10000) #rbinom(1000,1,pr) # bernoulli response variable\n",
    " \n",
    "X=np.column_stack([x1,x2])\n",
    "# standardize the features since regularization requires all features to be on same scale\n",
    "scaler = StandardScaler(copy=True)\n",
    "# we have created a standardization based on the training data\n",
    "X_train = scaler.fit(X).transform(X)\n",
    "y_train = y\n",
    "\n",
    "#now feed it to glm:\n",
    "#df = data.frame(y=y,x1=x1,x2=x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaler.fit(X).transform(X), y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=[0.0001,0.001,0.01,0.1,0.2,0.3]\n",
    "n_estimators=[50,100,150,200]\n",
    "max_depth=[2,4,6,8]\n",
    "param_grid=dict(learning_rate=learning_rate,max_depth=max_depth,n_estimators=n_estimators)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=7)\n",
    "grid_search=GridSearchCV(model,param_grid,scoring='neg_log_loss',n_jobs=-1,cv=kfold)\n",
    "#grid_result=grid_search.fit(X,y)\n",
    "grid_result=grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take forever\n",
    "#cross_val_score(grid_result, X_train, y_train, cv=10 ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=50, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = model.set_params( learning_rate= 0.1, max_depth= 4, n_estimators= 50 )\n",
    "u.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.557971  0.442029]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85510073940073938"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(u.feature_importances_)\n",
    "cross_val_score(u, X_train, y_train, cv=10 ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression Bayesian Inference approach :\n",
    "    - Pymc3 with Theano\n",
    "\n",
    "    Steps:\n",
    "        1. Prepare Data\n",
    "        2. Build Probabilistic Model\n",
    "        3. Condition Model on Data & Find the local maximum a posteriori point given a model (MAP)\n",
    "        4. Sample posterior distribution using MAP as starting points for Indepedent Variables(X's)\n",
    "        5. Generate posterior predictive samples from model given a Samples of posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -3,120.2, ||grad|| = 1.7939: 100%|██████████████████████████████████████████████| 14/14 [00:00<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beta': array(2.9168537609096776), 'beta0': array(1.9854704735996134), 'alpha': array(0.9053831851570006)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -3,120.2, ||grad|| = 1.7939: 100%|██████████████████████████████████████████████| 14/14 [00:00<00:00, 17.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [04:24<00:00,  5.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 715.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 2703.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1 Use theano shared variable so that we can make predictions for new values later\n",
    "log_dose_shared0 = shared(X_train[:, 0])\n",
    "log_dose_shared = shared(X_train[:, 1])\n",
    "\n",
    "# Sample size in each group. The sample size has to be a shared variable too\n",
    "# Each row/observation is a group so n = total in group. 1 if only one per group\n",
    "n_shared = shared(np.ones(len(X_train), dtype=int))\n",
    "\n",
    "# Outcomes/Target\n",
    "deaths = y_train\n",
    "\n",
    "\n",
    "# 2 Build Probabilistic Model\n",
    "with Model() as bioassay_model:\n",
    "\n",
    "    # Priors for unknown model parameters. e.g. Logit-linear model parameters\n",
    "    alpha = Normal('alpha', 0, sd=100)\n",
    "    beta = Normal('beta', 0, sd=100)\n",
    "    beta0 = Normal('beta0', 0, sd=100)\n",
    "\n",
    "    # Expected value of outcome. e.g. link function outcome. Calculate probabilities of Y/Target\n",
    "    theta = invlogit(alpha + beta * log_dose_shared + beta0 * log_dose_shared0 )\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations Data likelihood YTarget\n",
    "    obs_deaths = Binomial('obs_deaths', n=n_shared, p=theta, observed=deaths)\n",
    "\n",
    "    \n",
    "# 3 Finds the local maximum a posteriori point given a model. uses BFGS.\n",
    "from pymc3 import find_MAP\n",
    "# Runs fit to data returns parameters/coefficients\n",
    "map_estimate = find_MAP(model=bioassay_model)\n",
    "print(map_estimate)\n",
    "\n",
    "\n",
    "# 4 Now draw samples from the posterior using the given step methods.\n",
    "with bioassay_model:\n",
    "    \n",
    "    # obtain starting values via MAP\n",
    "    start = find_MAP(model=bioassay_model)\n",
    "    \n",
    "    # instantiate sampler\n",
    "    step = pm.Metropolis()\n",
    "    \n",
    "    # posterior of X's\n",
    "    # draw 1,000 posterior samples of independent variables\n",
    "    bioassay_trace = sample(1000, step=step, start=start)\n",
    "\n",
    "\n",
    "# 5 Generate posterior predictive samples from a model given a trace.\n",
    "from pymc3 import sample_ppc\n",
    "\n",
    "with bioassay_model:\n",
    "    deaths_sim = sample_ppc(bioassay_trace, samples=1000)\n",
    "    \n",
    "# take only last half  of posterior distr. of X's. other half was burn in.\n",
    "tr1 = bioassay_trace[500:]\n",
    "    \n",
    "#PREDICT\n",
    "log_dose_to_predict0 = X_train[:1000,0] #np.random.uniform(-0.8,0.7,size=50)\n",
    "log_dose_to_predict = X_train[:1000,1] #np.random.uniform(-0.8,0.7,size=50)\n",
    "n_predict = n = np.ones(1000, dtype=int)\n",
    "\n",
    "# Changing values here will also change values in the model\n",
    "log_dose_shared0.set_value(log_dose_to_predict0)\n",
    "log_dose_shared.set_value(log_dose_to_predict)\n",
    "n_shared.set_value(n_predict)\n",
    "\n",
    "# Simply running PPC will use the updated values and do prediction\n",
    "ppc = pm.sample_ppc(tr1, model=bioassay_model, samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804804\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy:',(ppc['obs_deaths']==y[:1000]).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 4242.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Changing values here will also change values in the model\n",
    "log_dose_shared0.set_value(np.array([ 0.93622719]))\n",
    "log_dose_shared.set_value(np.array([-1.2161206]))\n",
    "n_shared.set_value(np.array([1]))\n",
    "\n",
    "# Simply running PPC will use the updated values and do prediction\n",
    "ppc = pm.sample_ppc(tr1, model=bioassay_model, samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99812803417373919"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitInv= lambda x: np.exp(x)/(1.0+np.exp(x)) #sigmoid --> returns probability\n",
    "logitInv(0.9053831851570006 + 2.9168537609096776 * 0.08986007 + 1.9854704735996134 * 2.57440271)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40173059  0.59826941]\n",
      "0.827098030498\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=100,max_features='sqrt', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "print( cross_val_score(clf, X_train, y_train, cv=10 ).mean() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.1,  0.9]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.predict([[2.57440271,  0.08986007]]))\n",
    "clf.predict_proba([[2.57440271,  0.08986007]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.9741301   2.90014277]]\n",
      "0.857201540002\n"
     ]
    }
   ],
   "source": [
    "#logistic Regression\n",
    "logit = LogisticRegression(fit_intercept=True)\n",
    "\n",
    "# Fit model. Let X_train = matrix of predictors, y_train = matrix of variable.\n",
    "# NOTE: Do not include a column for the intercept when fitting the model.\n",
    "resLogit = logit.fit(X_train, y_train)\n",
    "print(resLogit.coef_)\n",
    "print(cross_val_score(resLogit, X_train, y_train, cv=10 ).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855100739401 0.827098030498 0.857201540002\n"
     ]
    }
   ],
   "source": [
    "print( cross_val_score(u, X_train, y_train, cv=10 ).mean() ,\n",
    "cross_val_score(clf, X_train, y_train, cv=10 ).mean(),\n",
    "cross_val_score(resLogit, X_train, y_train, cv=10 ).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4VFX6wPHvOzPplS4QkWBCbyLVAriKgAV1RcWuiz/s\nBZQFuy7rLihr721XRUFBxIZgAxRROkiH0HtvAQJJ5vz+OBMYQsokZHJnkvfzPPNk5t47d965Sead\nc+497xFjDEoppVRhXE4HoJRSKrRpolBKKVUkTRRKKaWKpIlCKaVUkTRRKKWUKpImCqWUUkXSRKEC\nJiLXi8j3TscRSkQkU0QaOPC69UXEiIinvF87GERkkYh0LcXz9G+yHGiiCFMiskZEDvk+qLaIyP9E\nJD6Yr2mM+dgYc2EwX8OfiJwlIj+LyH4R2SsiX4tI0/J6/QLimSwit/kvM8bEG2NWBen1GorIaBHZ\n4Xv/f4rIABFxB+P1SsuXsNJOZh/GmGbGmMnFvM4JybG8/yYrK00U4e1SY0w80Bo4A3jY4XhKpaBv\nxSLSCfge+BKoA6QC84HfgvENPtS+mYvI6cB0YD3QwhiTBFwFnAkklPFrOfbeQ+24q0IYY/QWhjdg\nDXCB3+NngW/9HkcBw4F1wFbgTSDGb/1lwDxgH7AS6OFbngS8B2wGNgL/BNy+dbcAU3333wCG54vp\nS2CA734d4HNgO7AauM9vu6eAMcAI3+vfVsD7+xV4vYDl3wEf+u53BTYAjwA7fMfk+kCOgd9zBwFb\ngI+AKsA3vph3++6n+LZ/BsgFsoBM4FXfcgOk+e7/D3gN+BbYj/2gP90vnguBZcBe4HVgSkHv3bft\nCP/fZwHr6/te+2bf+9sBPOq3vj3wO7DH97t8FYj0W2+Au4EVwGrfspewiWkfMBs41297t+84r/S9\nt9nAqcAvvn0d8B2Xa3zbX4L9+9oDTANa5vvbHQT8CRwGPPj9Pftin+WLYyvwvG/5Ot9rZfpunfD7\nm/Rt0wz4Adjle+4jTv+vVoSb4wHorZS/uOP/sVKABcBLfutfAL4CqmK/gX4N/Nu3rr3vw6obtlVZ\nF2jsW/cF8BYQB9QEZgC3+9Yd/acEOvs+VMT3uApwCJsgXL4PkieASKABsAro7tv2KSAbuNy3bUy+\n9xaL/VA+r4D3fSuw2Xe/K5ADPI9NCl18H1iNAjgGec8d5ntuDFANuNL3+gnAaGCc32tPJt8HOycm\nip2+4+sBPgZG+dZV933w/dW37n7fMSgsUWwBbi3i91/f99rv+GJvhf3QbeJbfybQ0fda9YElwAP5\n4v7Bd2zykucNvmPgAR70xRDtWzcQ+zfWCBDf61XLfwx8j88AtgEdsAnmZuzfa5Tf3+48bKKJ8VuW\n9/f8O3Cj73480DHfe/b4vdYtHPubTMAmxQeBaN/jDk7/r1aEm+MB6K2Uvzj7j5WJ/XZngJ+AZN86\nwX5g+n+b7cSxb45vAS8UsM9avg8b/5bHtcAk333/f0rBfsPr7Hv8f8DPvvsdgHX59v0w8F/f/aeA\nX4p4bym+99S4gHU9gGzf/a7YD/s4v/WfAY8HcAy6AkfyPggLiaM1sNvv8WSKTxTv+q27CFjqu38T\n8LvfOsEm2sISRTa+Vl4h6/M+NFP8ls0A+hSy/QPAF/ni/ksxf2O7gVa++8uAywrZLn+ieAMYkm+b\nZUAXv7/dvxXw95yXKH4BngaqF/KeC0sU1wJzg/l/V1lv2j8Y3i43xvwoIl2AT7DfWvcANbDfimeL\nSN62gv12B/ab3PgC9ncaEAFs9nueC/uBdhxjjBGRUdh/zl+A67DdJXn7qSMie/ye4sZ2J+U5YZ9+\ndgNeoDawNN+62thulqPbGmMO+D1ei23VFHcMALYbY7KOrhSJxbZCemBbSAAJIuI2xuQWEa+/LX73\nD2K/EeOL6eh79h2/DUXsZyf2vZbq9USkIbal1RZ7HDzYVp6/434HIvIQ0NcXqwESsX9TYP9mVgYQ\nD9jf/80icq/fskjffgt87Xz6Av8AlorIauBpY8w3AbxuSWJUJaAnsysAY8wU7LfZ4b5FO7DdQM2M\nMcm+W5KxJ77B/pOeXsCu1mNbFNX9npdojGlWyEuPBHqLyGnYVsTnfvtZ7bePZGNMgjHmIv+wi3g/\nB7DdD1cVsPpqbOspTxURifN7XA/YFMAxKCiGB7FdKx2MMYnY7jWwCabImAOwGdtSsju02Sul8M35\nEdsNVlpvYJNsuu+9PMKx95Hn6PsRkXOBv2OPbxVjTDK2ezLvOYX9zRRkPfBMvt9/rDFmZEGvnZ8x\nZoUx5lps1+cwYIzvd1zc8V+P7eZUZUwTRcXxItBNRFoZY7zYvusXRKQmgIjUFZHuvm3fA24VkfNF\nxOVb19gYsxl7pdF/RCTRt+50X4vlBMaYudgP5HeBicaYvBbEDGC/iAwSkRgRcYtIcxFpV4L3Mxj7\nrfQ+EUkQkSoi8k9s99HT+bZ9WkQifR92lwCjAzgGBUnAJpc9IlIVeDLf+q2U/oPoW6CFiFzuu9Ln\nbuCUIrZ/EjhLRJ4TkVN88aeJyAgRSQ7g9RKw50QyRaQxcGcA2+dgT+R7ROQJbIsiz7vAEBFJF6ul\niFTzrct/XN4B7hCRDr5t40TkYhEJ6GotEblBRGr4fod5f1NeX2xeCv8dfAPUFpEHRCTK93fTIZDX\nVEXTRFFBGGO2Ax9iTyCDvaokA/hDRPZhv6E28m07A3tS+AXst8Yp2O4CsH3pkcBibBfQGIruAvkE\nuMD3My+WXOwHdmvsFU95ySSpBO9nKtAde/J3M7ZL6QzgHGPMCr9Nt/ji3IQ9eXyHMSavu6rQY1CI\nF7EnhncAfwAT8q1/CduC2i0iLwf6XnzvZwe2hfQstlupKfbKnsOFbL8SmxTrA4tEZC+2xTYLe16q\nOA9huwP3Yz+4Py1m+4nY97sce6yzOL576Hns+Z/vsQnoPeyxAnvO6QMR2SMiVxtjZmHPWb2K/d1k\nYM8lBKoH9j1nYo95H2PMIWPMQezVZ7/5Xquj/5OMMfuxF2hciv27WAGcV4LXVYXIu2JFqbDjG8k7\nwhhTVBdOSBIRF/by3OuNMZOcjkepomiLQqlyIiLdRSRZRKI4ds7gD4fDUqpYQUsUIvK+iGwTkYWF\nrBcReVlEMnylCdoEKxalQkQn7FU5O7DdI5cbYw45G5JSxQta15OIdMZe5/+hMaZ5AesvAu7FXmve\nATtYTE88KaVUiAlai8IY8wt2GH1hLsMmEWOM+QNIFpFArhtXSilVjpwccFeX46+q2OBbtjn/hiLS\nD+gHEBcXd2bjxo0L3enh3MPk5OaQY3LI8eaQ680lx+u7b/zu+5bnegMdR6VUGJJjAyEEcMmx+0d/\n+m3jluOeevxPAY/Y61NPWOdbHyG29spxy4FIF+SaY691wvJC4vWPxeW/QAUschdE7oQ5hh3GmBql\n2UdYjMw2xrwNvA3Qtm1bM2vWrOPWr9u7jo///JiP/vyIJTuWFLiP5OhkqsVUo2pMVarGVKVabDWq\nRtv7SdFJeFweXOLCJS7c4j523+UucHlR6/yX560TEQQ5+hM4bhlQ5PrSPCeQ9ars7d4Nu3bBwYP2\nduAA7Ntnl+/YYZdlZ9vlWVnZYHZjvIcRDlI1eTHGm4XbfYhTamZw8GAcLtcRXK4jpNZbSuaBRE6v\nv5j9mUm43bm43Tl43Dm43TlUrbINt9uL1ysYI7jdXseOwcFDyXi9EXi9HnK9EYAQHbWHXXtOx2s8\nGN/N7TK43Uc4dLgOIi779ylue99l/29cLvvY5RIiI3aS4z0dETcudwR2SIoHIQsjydgST24Qt/2b\nFze2KrsLEZdveQ5IEi6//hT7uif+RMAlgssF4hJfQsyXygr4X8r7f/PfRvzW5r1mwfvx21I4YRsp\nYNuiliX//CtJ06ZTe+TotQX8qgLiZKLYiB1ynyfFtywg+w7vY8ziMXz050dMXjMZgLNPPZtXer5C\ngyoNbDLwJYbk6GTcrpAq4a/CgNcLe/fCzp3H33bssD937QKvdx8xMcvYtWsXkZEbOHzYEB+/lMOH\no4mOPkBq6kIyM5M55ZQ11E3Iom6CEBl5mJSU5Rw5EkVkZIHDKI6TnZ2EMZEY40YEDh9uSHzcHrKz\nGyESgcvlweWKICfHgx1Ok4ZIJF6vx/eh68Hlyrufict1qu/D1330Z0SEB7fbjcfjwu02REVVxe32\n4PG48Xg8REXZ/Yi48HiSgLzH7qOvcewDWb+EOGr3bnjoIWjQAB59FJq2h3uAkaX/vTiZKL4C7hFb\nL6gDsNc3MrhYczbPofN/O3Mg+wBpVdN4uuvT3NDyBhpU0dH7qnDGwLZt9gP+0CF7f9Mm2LIlm23b\nMtm7dwdu93wyM7NISMjg0KFIoqIOkpq6kISEXURGHsbtzqZFiwUcOhRPdPQBIiKyi3g9W2JJxEVE\nRDoih4mPb4jbHY/L1Ync3P3Ex7fC6z1CTEwabncM4CY+vgURETVwuWJ8y5QK0BdfwF13wfbt8Nhj\nZbbboCUKERmJrdBZ3Vf87ElswTmMMW9ii9JdhB21eRA7Ujgg/537X7zGy7S/TaNjSkf9BqMAyMmx\nXTybNsH69cduK1fCxo3b8XrnY0wmVapso2PHb4mP30OrVr/QoIjvF8a4MSYSkcOIVCEqqgMxMQ0R\n2Ud8fHNcrlg8nkQSEtricsUQGVkbtzsOjydZ/y5V+dm6Fe69F0aPhtat4dtvoU3ZjTgIu5HZbdu2\nNbtu3EWzms34+tqvnQ5HlRNjbBJYvRrWrYM9e2DLFnt/82aYPXs38fEZREbup2rVLdSqtZa0tHm0\nbj2JpKSduFwF9ddHERPTg6ioHKpW7YzHUwWRCBITO+LxJOLxVMXtji7396pUic2aBV262K6mgQMh\nIuKETURktjGmbWl2HxYns/1l5WSxes9qBp09yOlQVBnKzYVVq+DPP2HtWti4EdasgYULbVfR7t3g\n9Xpp3HgmDRr8SXT0QVJTF9Cs2RJ6955W4D5F4omPb4nH05qYmNNJTOxIdHQqUVF1iYpKweWKKt83\nqVRZWrsWvv4a7rkH2ra135qqVSv+eaUQdoliT5YtJnlxw4sdjkSV1t69MGMGTJwIy5bZ7qEVK+zV\nQJbhlFO207TpBq677neaN/+IxMTlRETsLnB/UVGnkZjYkapVuxMVVYeIiBrExKTh8SQWuL1SYc3r\nhTfegMGD7eMrr4TatYOWJCAME8XerL20PqU1KYlhVweu0snJgalTYfZsWLoUMjJgyhTbjZSUtJ3G\njefQvPlm2rffTOPGP5GQcJDo6AXYAf3HE4mievVriItrTnJyZ2JiGhIRUQ2X68QmtlIV1rJlcNtt\n9h+re3d46y2bJIIs7BLFgewD/KX+X5wOQ+WzaxfMnw+LF9vbvHnZbNmylnr15lC//iLq1NlC27br\neeihP4mN3YRIwefGkpK6EBFRlejo04iJSSM2tgnx8W2IiAhkCgalKrCDB+Gcc2w/7f/+BzfdVOAY\njmAIu0RhjKFqTFWnw6jUjLFdRb/8Ym+zZsGSJYYzzpjERRe9R5cuU7nqqnUnPM/jqQK4iIlpS1xc\nc5KSziYxsRPR0fVxuWL0KiGlCrJ8OaSnQ2wsfPSRvarplKLmvCp7YZcoAGIjYp0OodIwxl5uumiR\nbTHMnAm//grGrKF16yk0bLiCv/3tEG3avIzLlXP0eVFRKdStey9xcc1ISjoHtztRE4FSJZGVBUOG\nwLBhtgVxww3Qo4cjoWiiUMc5cMCeRxg3DjZsgLlz7WWoVapspWnT3znvvO/p02cqVasuOO55sbFN\nqVKlG3Xq3EFMTBouV1j+aSkVGn77Dfr2teckbr0VLnb24p2w/G/WRFF29u+3yWDqVPj+e/j9dzhy\nBCIisujR43/8618/kpr6+QnPS0o6lzp17iA5+TwiI2vZOjpKqZM3ZAg8+STUq2cvDbzwQqcj0kRR\nmWzfbq8+WrbMdiUtWGAvU92/H1yuXGrVWsvDD2fQpcsjiMw++rzq1a8gOvo0qlS5gOTk83C79fgr\nVeaMsSenW7e2o6yfeQbi452OCtBEUeGtXWtH9X/8Mcybd2x5TAy0b7+Df/zjTZo1+5qIiBknPPe0\n0x6nXr1HdHSyUsG0axf07w9pafD443DppfYWQjRRVEB798Lw4TBypK1zBNC+PTz77CFatpxFtWqf\ncOjQx+Tm7j/6nKSkc0lKOpf4+FYkJXUmKqp8r6pQqlIaMwbuvtsmi8cfdzqaQmmiqCCOHLEnoQcP\ntuMYsrKgVSt4+WUv5577EXv29MVOKQOZmeB2J1C79m2ccsotvoJ2Ws5CqXKzebMtvTF2LJx5pj1B\n2KqV01EVShNFmNu+3Q7OfO01e3VSRARccAE89dQK3O7rOHRoFXv22Blpk5LOpWbNa6latScxMfWd\nDVypymzTJnuietgwGDAAPKH9URza0RUiJqJy1+j3emHSJBgxAkaNsq2H7t3hjTd20qbNDLZte4TM\nTHtCwu1OomHDN6lR42oiIqo4HLlSldiaNbaI37332lbE+vVQJTz+J8MyUUS6I50Oodzl5NiBbuPG\n2blJ1q+H6Gi45ZbD9O37KsZ8yIEDf7Jqld0+MfFs0tNfJiGh7GrSK6VKITfXNvkfeQRcLrjqKjuy\nOkySBIRponBL5ZjW1Bg7/8J338Hzz9sy3NHR0K0bPPfcepo2HczOnZ+Q6auh5/FUIz39FZKTuxAV\nVcfZ4JVSsGSJLeI3bZodVf3WW+VefqMshGWicFXgwV3G2NpJY8fay1rzrlpq2xb+9S84//ylbNhw\nF3v2TGLnTrsuLe0V6tS5Q0dDKxVKDh6Ezp1tX/GHH9oSHGFaxiYsP1ncrorXojh4ED75xLZQ582z\n57bOPttOVtWhA9Sv/yurVg1i4cLfAahS5ULq13+axMT2OipaqVCydCk0amSL+H38sb2aqVYtp6M6\nKWH5CVORWhQbNtjZCxMS4P/+z7YoXn8dtm0zfPrpJ5xzTh/27BHmzevMvn2/ExvbmObNv6RVq4kk\nJXXUJKFUqDh0CAYNgmbNbIIAW34jzJMEhGmLoiIkiq1b7fiad96xj3v2tF2Zl166jx07xjJ//q1H\nt61S5QKiok6lQYOhREbWdChipVShfvnF/gOvWGF/XnKJ0xGVqbBMFOF8Mjs31w7GvO8+2LHDzmL4\n8MPZ1Kr1JqtWDea3347OB0qNGr1p2PAdnbRHqVD29NPw1FOQmgo//gjnn+90RGUuLBNFuLYo5s2z\n57MWLbJdmN99Bykpn7FixX1kZGwFIDKyLqed9ijJyV2Ji2vicMRKqULlFfFr29bWahoyBOLinI4q\nKMSYgqekDFVSR8zBtQfDatDd7t3w8sv2qqX4eHjpJbj44mksWnQpOTl21HR6+qvUrn27XrmkVKjb\nscMmhvR0eOIJp6MJmIjMNsa0Lc1zw/Krebhc9bR9u+1aqlHDtkyvuAJmzvycBg3qMH/+2eTk7CIx\nsRPt2y+lbt27NUkoFcqMgc8+g6ZNbUkEV1h+fJZKWH4yhXrXU06Ondp24EDYtw9uvhn69fuGQ4cu\nZZ1vKumIiJo0bTqKKlXOczZYpVTxNm2Cu+6CL7+0XU0//ggtWzodVbkJy0QRyiezZ8yAm26ykwN1\n7Ahvv72HffsacejQNgCio1Np3XoS0dGnORypUipgW7bAzz/Dc8/BAw+EfBG/shbaX80LISE4unHf\nPrjjDjs4bu9e+O9/DZ9+Opxdu2qQnW2TRIcOGXTsuEqThFLhYNUqePFFe79NG1i3Dh56qNIlCQjH\nk9l1xZiNoRVzdrZtPcyZA7ffbhg8+BPWrLnh6PqmTUdRs+Y1DkaolApYbq69+uTRR23d/mXLwrI+\nU34nczI77FKjEFqtiTlz4PLLbTXXl146RMuWsaxZY9fFxDSkffulIdkCUkoVYNEi6NsXpk+Hiy+G\nN9+sEEniZIVdogglv/1mR1Tv3w9ffz2bxMTOeL12XefOWTprnFLh5OBB6NLFjo345BPo0ydsi/iV\ntbA8RxEKfv3VlnGpXRuWL99MfHxbvN6D1Kp1E127Gk0SSoWLxYvtpa+xsfay18WL4dprNUn4CbtE\n4XTXkzHw7LNw3nk2SXz//XK2bm0GQJMmI2jS5ANH41NKBejgQXsNe4sWdrpIsPMI16jhbFwhKOwS\nhZN54sABuPFGWyDyr3+FyZMns3p1I3JydpOa+k9q1breueCUUoGbPNmW/x4+3JZt7tXL6YhCmp6j\nCNCiRbbLctEiGDLkCFdddT8ZGW8CkJb2Mikp9zocoVIqIE8+Cf/4B5x+uh0bcZ4Oei2OJooAbNli\nZzHcvx8mThxNZOR1bN6cg8dThUaN3qNGjSucDlEpVZy8In7t28ODD9pkERvrdFRhIahdTyLSQ0SW\niUiGiAwuYH2SiHwtIvNFZJGI3FrQfpz0xx9wzjm2sN/48cuJiLgaY3JISenP2Wfv0CShVKjbvh2u\nu84mBrCXvQ4frkmiBIKWKETEDbwG9ASaAteKSNN8m90NLDbGtAK6Av8RkchgxVRS48fbVmlmJnz3\nnSEy8loA2radR1ra8zq7nFKhzBh7mWuTJnYSmMiQ+WgJO8H8pGsPZBhjVhljjgCjgMvybWOABLEj\n0uKBXUBOEGMK2Acf2GqvKSkwdSrUrfs4mZlzqF79r8THt3I6PKVUUTZssCeor78e0tJg7lx4+GGn\nowpbwUwUdYH1fo83+Jb5exVoAmwCFgD3G2O8+XckIv1EZJaIzCqPkiMffQS33AJnn22TxKmnbmHd\numcAaNxYL39VKuRt326nJ33+eTsytlkzpyMKa073nXQH5gF1gNbAqyKSmH8jY8zbxpi2xpi2wS6H\nMX063HkndO4MEyeCyGf8/nttwNZs8njig/r6SqlSysiAF16w9884w9bV6d8f3KFbbTpcBDNRbARO\n9Xuc4lvm71ZgrLEygNVA4yDGVKTp0+10t3FxtmszO3sFixdfg9udRJMmI7Swn1KhKCfHnpxu0cLO\nX73VTitM4gnfOVUpBTNRzATSRSTVd4K6D/BVvm3WAecDiEgtoBGwKogxFeqnn+Avf4FateyVTnXr\nwsqVDwLQuPH7OphOqVC0YAGcdZYdYX3hhXagU61aTkdV4QRtHIUxJkdE7gEmAm7gfWPMIhG5w7f+\nTWAI8D8RWYAdcz3IGLMjWDEV5sgR6NcP6tWDSZOgVq1cZs3qQGbmbKKjT6d69fzn4JVSjjt40F6W\n6HLZGk1XX631mYIkqAPujDHjgfH5lr3pd38TcGEwYwjEiy/aOUrGj7cVhadNO40jR2wvWatWPyIh\nPKOeUpXOwoX25HRsLHz6qS3FUb2601FVaE6fzHbcmDH2qrlu3ezo63XrnuPIkY2IRNKlSw4xMfWd\nDlEpBbbY2oABdq7qvCJ+55+vSaIcVOoSHtOn2yJ/rVvDF1/YcxIbNjwPQNu2c7QloVSo+OknW7xv\n9Wq46y64TLuDy1OlbVGsXg2XXmpLhY8ZA9nZvxxNEh06ZBAXp9ddKxUSHn/clv/2eGDKFHjtNb2i\nqZxVykRhjO1mys625yVSUvYwb14XAFq2/J6YmNMdjlApdXS6yLPOgr//HebPtwOcVLmrlInixRdh\n+XJ47DFo3BiWLr0RgPT016latZvD0SlVyW3bZmv6P/20fdyzJwwbBjExzsZViVW6RJGdDUOHQsOG\ndtDmtm2fsnPnNyQmnk3dunc6HZ5SlZcx9iR1kyb2pKFWdw0Zle5k9siR9gvL8OFw6NBSFi/uA0B6\n+ssOR6ZUJbZ+Pdxxh+0L7tQJ3n0XmuYvNq2cUulaFGPH2i8ql1++kJkzmwCQmvoMCQltHI5MqUps\n505bvO+ll+DXXzVJhBgpj2qsZcmd4ja5G3JL9dy1a+3shwMGwCWXxOL1HiIl5UHS0oaXcZRKqWIt\nXw5ffQUPPWQf798PCQnOxlSBichsY0zb0jy3UrUoHnwQIiLg5ps/xes9RFTUaZoklCpvOTn25HTL\nlvDMM8eK+GmSCFmVJlFMnQqffw6DBxu2b78OgNatJzsblFKVzfz50KEDDB4MF10EixdrEb8wUClO\nZufmwl//CvXqZdG9+xlkZXmpUuUCLc+hVHk6eNCW3PB47CjXK690OiIVoEqRKF57zU54NWlSDFlZ\nkJDQjhYtxhf/RKXUyfvzTztXRGwsjB5ti/hVrep0VKoEKnzXk9cLr7wCLVv+AYDLFc2ZZ87A5Ypw\nODKlKrjMTLj/fltM7aOP7LLzztMkEYYqfIvigw/sDInffPMGAK1aTXI4IqUqgR9+sJO8rFkD99wD\nV1zhdETqJATUohCRSBFJC3YwwTBuHJxyymri4j4EIDGxncMRKVXBPfqonW0uKsqOiXjlFb2iKcwV\nmyhE5GJgAfCD73FrEfki2IEVJtodHfC2a9fChAnZjBzZAIAWLb7R0uFKBUteEb9zzrGTvMybZ++r\nsBdIi+IfQAdgD4AxZh7gWOuiSY0mAW87YgTceusjAERH16datYuDFZZSldeWLdC7Nzz1lH3csyf8\n618QHfiXOhXaAkkU2caYPfmWhfxw7u3b4T//gSuueBuAdu0WOxyRUhWMMfC//9lyG998o3NEVGCB\nnMxeIiJXAy4RSQXuA/4Iblgnb8AA2L0boqL2ccopt+B2a4lipcrM2rX2ZPX339vupXffhUaNnI5K\nBUkgLYp7gDMBLzAWOAzcH8ygTtbSpXbO9SFDxgAQHd3A4YiUqmD27IGZM+HVV+2sc5okKrRAWhTd\njTGDgEF5C0Tkr9ikEZJGjbLzTlxwwWiysiAlJaTzmlLhYdkyW8Rv4EA7aG7dOoiPdzoqVQ4CaVE8\nVsCyR8s6kLL044/QsaMhO3s8IpF4PNp3qlSpZWfDv/9tk8PQoXZCF9AkUYkU2qIQke5AD6CuiDzv\ntyoR2w0VkrKyYNYseOSR2eTmZlKr1g1Oh6RU+Jo7F/r2tT9797ZdTTVrOh2VKmdFdT1tAxYCWcAi\nv+X7gcHBDOpkTJ8Ohw/DWWc9A0CdOnc7HJFSYergQejWzdbm//xzW1lTVUqFJgpjzFxgroh8bIzJ\nKseYTsrqS+p3AAAgAElEQVSkSeB2Z+PxjAMgMbGDwxEpFWbmzrX1mWJjbZXXVq2gShWno1IOCuQc\nRV0RGSUif4rI8rxb0CMrpenT4eKLfwCgRo1rEBGHI1IqTOzfb+sytWlzrIhf166aJFRAieJ/wH8B\nAXoCnwGfBjGmUsvJsRMUXXWVHWTXoMFQhyNSKkxMmADNm8Prr9uKr9rNpPwEkihijTETAYwxK40x\nj2ETRsiZM8dWNk5J+ZL4+DN0YiKlAvHww7bsRlwc/PYbvPiiXtGkjhPIOIrDIuICVorIHcBGICRL\nQQ4fDp07TwDs5ERKqSLk5oLbbbuXPB547DFb8VWpfAJpUfQH4rClO84G/g/4WzCDKg1j7ORZF144\nHYBTT33Q4YiUClGbN9uupbwift27w5AhmiRUoYptURhjpvvu7gduBBCRusEMqjQ+/9z+bNPGlu2I\niUl3MBqlQlBeEb8BA+yAIy0BrgJUZItCRNqJyOUiUt33uJmIfAhML+p5ThgwAGrXhri4DBIS2unV\nTkr5W7PGTib0t7/Z+avnz7f/NEoFoNBEISL/Bj4GrgcmiMhTwCRgPtCwXKIL0Lp1sH493HDDPrze\nLKpUudDpkJQKLXv32qs9Xn8dJk+GhiH1L6xCXFFdT5cBrYwxh0SkKrAeaGGMWRXozkWkB/AS4Abe\nNcaccL2qiHQFXgQigB3GmC4liB+ATz6xP/v23cTmzRARUb2ku1Cq4lm82BbxGzz4WBG/uDino1Jh\nqKiupyxjzCEAY8wuYHkJk4QbeA17KW1T4FoRaZpvm2TgdaCXMaYZcFUJ4wfs2InmzcHjeQ+AuLhm\npdmNUhXDkSPwz3/CGWfYSwHzivhpklClVFSLooGI5JUSFyDV7zHGmOJG5LQHMvKSi4iMwrZS/Kea\nuw4Ya4xZ59vnthLGD8Dq1bYlnZ29C4AqVS4ozW6UCn+zZtkifn/+CX36wEsvaRE/ddKKShRX5nv8\nagn3XRfbXZVnA3bubX8NgQgRmYwdm/GSMebD/DsSkX5AP4B69eodty4ry05UdP75sH//bGJi0vVE\ntqqcDhywl7pGR8OXX0KvXk5HpCqIoooC/lROr38mcD4QA/wuIn8YY46rJWWMeRt4G6Bt27bHzdc9\ndy54vdC+/WYOHJhPVFRKOYStVAiZM8cW8YuLgy++gJYtITnZ6ahUBRLIgLvS2gic6vc4xbfM3wZg\nojHmgDFmB/AL0KokL3L4sG/nKbYhUq9eSM+ppFTZ2bcP7roLzjwTRoywyzp31iShylwwE8VMIF1E\nUkUkEugDfJVvmy+Bc0TEIyKx2K6pJSV5kSNH7E+RzwCoXTvkBo0rVfbGj4dmzeCtt+x4iCvz9xQr\nVXYCqfUEgIhEGWMOB7q9MSZHRO4BJmIvj33fGLPIVy8KY8ybxpglIjIB+BM7a967xpiFJXkDy5fn\nvd4cIiPr4HJFluTpSoWfQYPg2WehaVM7X0QHnXNFBVexiUJE2gPvAUlAPRFpBdxmjLm3uOcaY8YD\n4/MtezPf4+eA50oStL+ffoLTTssFoGpVHWinKihj7Mk4t9teuREdDY88ovWZVLkIpOvpZeASYCeA\nMWY+cF4wgyqJjAxo1SobgJiYRg5Ho1QQbNwIl18OTz5pH194ITz9tCYJVW4CSRQuY8zafMtygxFM\nSRkDa9fCqafamVq120lVKMbAO+/YLqbvv4fqWnFAOSOQcxTrfd1Pxjfa+l4gJKZC3bPHzt54xhmT\nfUt0/ISqIFavtgPnJk2y80W88w6kpTkdlaqkAmlR3AkMAOoBW4GOvmWO27DB/qxT5zsAqlW71MFo\nlCpDmZl2dPVbb9kTcZoklIMCaVHkGGP6BD2SUshLFHFxgtcLsbH6z6TC2MKFtojfI4/YUuDr1kFs\nrNNRKRVQi2KmiIwXkZtFJKSmQM1LFG73b0RFneZsMEqV1pEj9uR0mzbwwgvHivhpklAhothEYYw5\nHfgnttTGAhEZJyIh0cLYsAHc7hyysxfi8SQ5HY5SJTdzph1Z/dRTcNVVtjS4FvFTISagkdnGmGnG\nmPuANsA+7IRGjlu6FDp3ngFAjRrFFbNVKsQcOAA9esDu3bbL6eOPoUYNp6NS6gTFJgoRiReR60Xk\na2AGsB04K+iRFSMnB777Dnr2nA1AlSrdHY5IqQDNmmUHz8XF2SqvixbBpXohhgpdgbQoFmKvdHrW\nGJNmjHnQGOP4nNkbN9pLYxs1mgdAXFzTYp6hlMP27oXbb4d27Y4V8TvnHEjSblMV2gK56qmBMcYb\n9EhKaN06+zMhYQLgwuNJdDQepYr09ddwxx2wZQs89BD07u10REoFrNBEISL/McY8CHwuIib/+gBm\nuAuqVasgOvoAIpuIiytRZXKlytfAgXZK0hYtYNw426JQKowU1aL41PezpDPblYuVKyE+fh8Ader8\nn8PRKJWPMZCbCx6Prc2UmGirvkZqmRkVfoqa4W6G724TY8xxycJXPrw8ZsArVEYGtG69Oi8iJ0NR\n6ngbNsCdd9qZ5p55Brp1szelwlQgJ7MLmgmob1kHUlKbNkGjRisBiItr4XA0SmGvZHrrLVvE7+ef\n4ZRTnI5IqTJR1DmKa7Cz0qWKyFi/VQnAnmAHVpydO6F58wkAREXVdTgaVemtWgV/+xtMmWLni3j7\nbWjQwOmolCoTRZ2jmIGdgyIFeM1v+X5gbjCDCsT27VC9+jIAoqNTHY5GVXoHDthR1e++axOGaHeo\nqjiKOkexGlgN/Fh+4QTm0CHYuhWqV59NQkI7RP8plRMWLLAD5h57zF7RtHYtxMQ4HZVSZa7QcxQi\nMsX3c7eI7PK77RaRXeUX4okyMsDlygEgIaGtk6GoyujwYXjiCVvE7+WXjxXx0yShKqiiup7ypjsN\nuWm1liyBDh3sHBRRUac6HI2qVP74w04otHgx3HijrfZarZrTUSkVVEV1PeWNxj4V2GSMOSIi5wAt\ngRHY4oCO2LABGjeeCUD16r2cCkNVNgcOwMUX2xpN48dDz55OR6RUuQjk8thx2GlQTwf+C6QDnwQ1\nqmKsXAmtWk0DICamoZOhqMpg+vRjRfy+/toW8dMkoSqRQBKF1xiTDfwVeMUY0x9w9HrUlSshKiqC\niIjquFwRToaiKrI9e+C226Bjx2NF/M46CxJCav4upYIuoKlQReQq4Ebgct8yRz+dly+H1NRpxMa2\ndDIMVZGNGwd33WVPVA8aZCcVUqqSCnRk9nnYMuOrRCQVGBncsArn9cLq1ZCbm0QIFrVVFcGAAXDF\nFXamuenTYehQvaJJVWrFtiiMMQtF5D4gTUQaAxnGmGeCH1rBcnIgIWEXsbHriY+/2KkwVEXjX8Tv\noovslUx//ztEaNemUsUmChE5F/gI2IitvneKiNxojPkt2MEVxOuFBg3+BCAq6jQnQlAVzbp1dq6I\nM86wRfwuuMDelFJAYF1PLwAXGWPONsacBVwMvBTcsAp3+DBERR0CID5eiwGqk+D1wuuvQ7NmtkZT\nnTpOR6RUSArkZHakMWZx3gNjzBIRcayo/pEjkJq6ENDBduokZGTYmky//mpLgL/9NtSv73RUSoWk\nQBLFHBF5EzvIDuB6HCwK6PVCcvJ2AKKj6zsVhgp3WVn28rn//hduvlmL+ClVhEASxR3AfcDffY9/\nBV4JWkTFMAaaN7enR9zueKfCUOFo3jxbxO/JJ6F5c1izBqKjnY5KqZBXZKIQkRbA6cAXxphnyyek\nohkDTZr8gdudjEggp1hUpZeVBUOGwLBhUL26nX2uZk1NEkoFqKjqsY9gy3dcD/wgIgXNdFfucnK8\nuN1eYmPTnQ5FhYNp0+zVTP/6F9xwgy3mV7Om01EpFVaKalFcD7Q0xhwQkRrAeOD98gmrcG73AQCq\nV7/M4UhUyDtwAC69FOLjYcIE6N7d6YiUCktFJYrDxpgDAMaY7RIy/TwGgOTkrs6GoULX779Dhw62\niN8339jzEVqfSalSK+rDv4GIjPXdvgBO93s8tojnHSUiPURkmYhkiMjgIrZrJyI5ItK72IBdh30/\ntaSCymf3bnvJ61lnwUcf2WWdOmmSUOokFdWiuDLf41dLsmMRcWPn2u4GbABmishX/mMy/LYbBnwf\nyH69XtuiiIgIufmUlJPGjoW777aTqT/8MFxzjdMRKVVhFDVx0U8nue/22LpQqwBEZBRwGbA433b3\nAp8D7QLZaV6i8HiSTzI8VWH07w8vvgitW9sJhc44w+mIlKpQAhlHUVp1gfV+jzcAHfw3EJG6wBXY\n6rSFJgoR6Qf0A6hTpwoALpde2lip+Rfxu+QSeyXTQw9pET+lgsDpE9QvAoNMMfXCjTFvG2PaGmPa\ner02t7lcjlURUU5bswZ69IDHH7ePzz/fdjdpklAqKAJOFCISVcJ9b8TOt50nxbfMX1tglIisAXoD\nr4vI5RTBGENWlqMT7CmneL3wyiv2KqZp0+A0rR6sVHkoNlGISHsRWQCs8D1uJSKBlPCYCaSLSKqv\niGAf4Cv/DYwxqcaY+saY+sAY4C5jzLiidhoRkYXLFcweMxWSVqyAzp3hvvvg3HNh4UJbGlwpFXSB\ntCheBi4BdgIYY+ZjzykUyRiTA9wDTASWAJ8ZYxaJyB0iUur/cBGDx7O9tE9X4erIETtZ+ocf2hPW\n2ppQqtwE8tXcZYxZK8dX18wNZOfGmPHYEd3+y94sZNtbAtknQE5O+0A3VeFs7lxbxO+pp+ycEWvW\nQFRJe0CVUicrkBbFehFpDxgRcYvIA8DyIMdVKI8nGxEdbFehZWXZk9Pt2sFbb9mxEaBJQimHBJIo\n7gQGAPWArUBH3zJHuN05uN27nHp5FWxTp0KrVjB0KNx0ky3iV6OG01EpVakV2/VkjNmGPREdEoxx\nERHR2OkwVDBkZsJll0FiInz/vZ15TinluGIThYi8Q14lPj/GmH5BiSgAHk+sUy+tgmHqVFufKT4e\nvv3WXv4ar5NSKRUqAul6+hH4yXf7DagJHA5mUEUzuFxOjxNUZWLnTtu9dO65x4r4deyoSUKpEBNI\n19On/o9F5CNgatAiKoYIuFxup15elQVjYMwYuOce2LXLjrDuEzK9m0qpfEozci0VqFXWgQROWxRh\nr39/eOklOPNMey6iVSunI1JKFSGQcxS7OXaOwgXsAgqdW6I8uN2aKMKOMZCTY+sx9eoFderAgAG2\nqJ9SKqQV+V8qdpRdK47VaPIaY044sV2eRAwxMZoowsrq1dCvn21BDB0Kf/mLvSmlwkKRn7i+pDDe\nGJPruzmaJPLYuY5UyMvNtV1MzZvD9OnQoIHTESmlSiGQr+bzRCRkZoIRMRgTUAUR5aTly+3VTA88\nAF26wKJFtlWhlAo7hXY9iYjHV9jvDOw0piuBA4BgGxttyinGE7hcWsoh5OXkwNq1MGIEXHedvVxN\nKRWWijpHMQNoA/Qqp1gCFh1d3+kQVEFmzbJF/IYMgaZNYdUqrc+kVAVQVNeTABhjVhZ0K6f4CuT1\nHnHy5VV+hw7B3/8OHTrA++9rET+lKpiiWhQ1RGRAYSuNMc8HIZ6AREenOvXSKr8pU+C22yAjA/7v\n/+DZZyE52emolFJlqKhE4Qbi8bUsQonLpXMjh4TMTPjrX21i+OknveRVqQqqqESx2Rjzj3KLpERC\nLndVLr/+CmefbWsyffednVQoLs7pqJRSQVLsOYrQpAPuHLFjB9xwg527Oq+IX/v2miSUquCKalGc\nX25RlJDopZblyxj47DO4917YvRuefFKL+ClViRSaKIwxITuNnCaKcnb//fDKK3Zq0p9+ghYtnI5I\nKVWOwrQim3Y9BZ0xkJ0NkZFwxRVw2ml2lLVby6coVdmE6SeutiiCauVKOP98eOwx+/i88+DBBzVJ\nKFVJhWWi0K6nIMnNheeft11Ls2dDo0ZOR6SUCgFh2fUkEpb5LbQtXQo33wwzZsCll8Ibb0Dduk5H\npZQKAWGZKLTrKQi8Xti0CUaOhGuu0SJ+SqmjwjJRaIuijMyYYYv4PfOMLeK3cqU9ea2UUn7CNFHo\nt92TcvAgPPEEvPAC1K5tr2aqUUOThApIdnY2GzZsICsry+lQVAGio6NJSUkhIqLsSh2FZaLQrqeT\nMGmSLeK3ahXcfjsMGwZJSU5HpcLIhg0bSEhIoH79+vqlLcQYY9i5cycbNmwgNbXsiqeGaaJQpZKZ\nCVddZYv4TZoEXbs6HZEKQ1lZWZokQpSIUK1aNbbnlfovI2HZ2R8RUcXpEMLL5Mn2ZHVeEb8//9Qk\noU6KJonQFYzfTVgmCp0KNUDbt8O119oBcyNG2GXt2kFsrLNxKaXCSlgmCj1HUQxj4JNPoEkTGDvW\nTk2qRfxUBTNu3DhEhKVLlx5dNnnyZC655JLjtrvlllsYM2YMYE/EDx48mPT0dNq0aUOnTp347rvv\nTjqWf//736SlpdGoUSMmTpxY4Dbz58+nU6dOtGjRgksvvZR9+/Ydt37dunXEx8czfPjwk46nrIVl\notBWbzHuvReuvx7S02HuXFuKQ69oUhXMyJEjOeeccxg5cmTAz3n88cfZvHkzCxcuZM6cOYwbN479\n+/efVByLFy9m1KhRLFq0iAkTJnDXXXeRm5t7wna33XYbQ4cOZcGCBVxxxRU899xzx60fMGAAPXv2\nPKlYgiVMT2ZrpjiB1ws5OTYh9O4NaWk2YWh9JhVEDzwA8+aV7T5bt4YXXyx6m8zMTKZOncqkSZO4\n9NJLefrpp4vd78GDB3nnnXdYvXo1Ub753GvVqsXVV199UvF++eWX9OnTh6ioKFJTU0lLS2PGjBl0\n6tTpuO2WL19O586dAejWrRvdu3dnyJAhgG0dpaamEheic7sEtUUhIj1EZJmIZIjI4ALWXy8if4rI\nAhGZJiKtAtxzWYca3lassNOQPvqofdy1q1Z6VRXal19+SY8ePWjYsCHVqlVj9uzZxT4nIyODevXq\nkZiYWOy2/fv3p3Xr1ifchg4desK2Gzdu5NRTTz36OCUlhY0bN56wXbNmzfjyyy8BGD16NOvXrwds\n0hs2bBhPPvlksXE5JWgtChFxA68B3YANwEwR+coYs9hvs9VAF2PMbhHpCbwNdAhWTBVOTo796vX4\n4xAVBTfd5HREqpIp7pt/sIwcOZL7778fgD59+jBy5EjOPPPMQq/4KemVQC+88MJJx5jf+++/z333\n3ceQIUPo1asXkb7u4Keeeor+/fsTHx9f5q9ZVoLZ9dQeyDDGrAIQkVHAZcDRRGGMmea3/R9ASmC7\n1hYFS5bYxDBrFlx2Gbz+OtSp43RUSgXdrl27+Pnnn1mwYAEiQm5uLiLCc889R7Vq1di9e/cJ21ev\nXp20tDTWrVvHvn37im1V9O/fn0mTJp2wvE+fPgwefHznSN26dY+2DsAOSKxbQEHNxo0b8/333wO2\nG+rbb78FYPr06YwZM4a///3v7NmzB5fLRXR0NPfcc09gB6Q8GGOCcgN6A+/6Pb4ReLWI7R/y3z7f\nun7ALGBWw4aYrKzNptJbvNiYU0815tNPjfF6nY5GVSKLFy929PXfeust069fv+OWde7c2UyZMsVk\nZWWZ+vXrH41xzZo1pl69embPnj3GGGMGDhxobrnlFnP48GFjjDHbtm0zn3322UnFs3DhQtOyZUuT\nlZVlVq1aZVJTU01OTs4J223dutUYY0xubq658cYbzXvvvXfCNk8++aR57rnnTioeYwr+HQGzTCk/\nz0PiqicROQ/oCwwqaL0x5m1jTFtjTFvf9uUZXuj44w94+GF7v0kTW8Tv6qv1MjBVqYwcOZIrrrji\nuGVXXnklI0eOJCoqihEjRnDrrbfSunVrevfuzbvvvkuSr0zNP//5T2rUqEHTpk1p3rw5l1xySUDn\nLIrSrFkzrr76apo2bUqPHj147bXXcPvOD952223MmjXraNwNGzakcePG1KlTh1tvvfWkXrc8iU00\nQdixSCfgKWNMd9/jhwGMMf/Ot11L4AugpzFmeXH7bdRIzIIFW4mMrBmEqEPUgQP2EteXXoKUFDup\nUI0aTkelKqklS5bQpEkTp8NQRSjodyQis/O+bJdUMFsUM4F0EUkVkUigD/CV/wYiUg8YC9wYSJKo\nlH78EZo3t2cN77oLFi3SJKGUKldBO5ltjMkRkXuAiYAbeN8Ys0hE7vCtfxN4AqgGvO7rTsoJLONV\nkq6WzEw7orpqVfjlFzj3XKcjUkpVQkEdcGeMGQ+Mz7fsTb/7twG3lXzPFTxR/PwzdOlii/hNnGgn\nFYqJcToqpVQlFRIns5XP1q325PT55x8r4nfmmZoklFKOCstEUeGuejIGPvrIthzypia97jqno1JK\nKSBsaz1VMHffDW+8AZ06wXvv2UtflVIqRIRpoqgALQqvF7KzbemNa66xyeGuu7Q+k1Iq5IRl11PY\nJ4ply+zJ6rwifl26aKVXpUqoPOajGD16NE2aNOG88847qVhHjx5Ns2bNcLlcRwfgFWTChAk0atSI\ntLS04woQ7tq1i27dupGenk63bt1OKFMSbGHaoghT2dnwn//AU0/ZE9S3leKCL6VCyAMTHmDelrKt\nM976lNa82KP4aoP+81EEUmYcjp+PIioqiq1btzJlypRCt3/vvfd45513OOeccwKOvyDNmzdn7Nix\n3H777YVuk5uby913380PP/xASkoK7dq1o1evXjRt2pShQ4dy/vnnM3jwYIYOHcrQoUMZNmzYScVU\nEtqiKC+LFkGHDrYEx8UX26J+N9/sdFRKhaW8+Sjee+89Ro0aFdBz8uajeOWVVwKaj+If//gHU6dO\npW/fvgwcOPCk4m3SpAmNGjUqcpsZM2aQlpZGgwYNiIyMpE+fPkfLkn/55Zfc7Pu8uPnmmxk3btxJ\nxVNS2qIoL2437NoFY8bAlVc6HY1SZSKQb/7BUNB8FGeeeWaRzynJfBQATzzxBD///DPDhw+nbdvj\nxwHv37+fcwsZAPvJJ5/QtGnTwN6In4LmtZg+fToAW7dupXbt2gCccsopbN26tcT7PxlhmSjC5vLY\nadPs5a7DhkHjxpCRAZ6wPORKhZRgz0dRnISEBOaV9dR+ARKRcv8MDNNPrRBPFJmZ8Mgj8OqrUK8e\nDBwI1atrklCqDJTHfBTFCUaLoqh5LWrVqsXmzZupXbs2mzdvpmbN8i2KGqbnKELY99/bIn6vvgr3\n3AMLF9okoZQqE2PGjOHGG29k7dq1rFmzhvXr15Oamsqvv/5Keno6mzZtYsmSJQCsXbuW+fPn07p1\na2JjY+nbty/3338/R44cAWD79u2MHj26xDHktSgKupUmSQC0a9eOFStWsHr1ao4cOcKoUaPo1asX\nAL169eKDDz4A4IMPPuCyyy4r1WuUVpgmihBtUWRmwvXXQ3Q0/PorvPyyrdeklCozoTYfRSC++OIL\nUlJS+P3337n44ovp3r07AJs2beKiiy4CwOPx8Oqrr9K9e3eaNGnC1VdfTbNmzQAYPHgwP/zwA+np\n6fz4448nzLIXbEGbjyJYGjUSs2jRfjyeEPoA/uEH+Mtf7AnruXPt4LnoaKejUioodD6K0BdO81FU\nfJs32yuYLrwQPv7YLjvjDE0SSqkKJSzPrjp+1ZMx8MEH0L8/HDoEQ4dqET+lwliHDh04fPjwccs+\n+ugjWrRo4VBEoSUsE4Xj7rwT3noLzjkH3n0XihlIo5QKbXnjFVTBwjRRONCi8C/id9110LIl3HEH\nuLT3TilVsYXpp1w5J4olS+w0pI88Yh937mwrvWqSUEpVAvpJV5TsbPjXv6B1a1i61J6oVkqpSka7\nngqzaBHccAPMmwdXXQWvvAK1agX/dZVSKsSEZYvC5YoM/ot4PLB3L4wdC599pklCqRBTHvNR1K9f\nnx07dpRZzKtXr6ZDhw6kpaVxzTXXHB0hnt+gQYNo3rw5zZs359NPPz1h/X333Ud8OQ7mDbsWhdfr\nQiRI+e3XX20Rv+HD7ZVMy5drfSalirBixQNkZpZtcbz4+Nakp4fGfBRlbdCgQfTv358+ffpwxx13\n8N5773HnnXcet823337LnDlzmDdvHocPH6Zr16707Nnz6AjyWbNmlfvERWHZoihz+/fbeas7d7Yt\niLxvEJoklApJ5TEfRVkzxvDzzz/Tu3dvoPB5JRYvXkznzp3xeDzExcXRsmVLJkyYANjJjQYOHMiz\nzz5bLjHn0U/C776D22+HDRvggQfgn/+EuDino1IqLATyzT8YymM+ikAsW7aMa665psB1kydPJjk5\n+ejjnTt3kpycjMf3BTQlJYWNGzee8LxWrVrx9NNP8+CDD3Lw4EEmTZp0tNDgq6++Sq9evY7OTVFe\nKnei2L8fbroJata0c0d07Oh0REqpADg9H0WeRo0alfm8FBdeeCEzZ87krLPOokaNGnTq1Am3282m\nTZsYPXo0kydPLtPXC0TlSxTGwMSJ0K0bJCTAjz/aSYV8TVGlVGgLhfko8pSkRVGtWjX27NlDTk4O\nHo/nuPkm8nv00Ud59NFHAbjuuuto2LAhc+fOJSMjg7S0NMB2paWlpZGRkVEm76VIxpiwuqWluUyp\nbdpkzOWXGwPGfPBB6fejVCW2ePFiR1//rbfeMv369TtuWefOnc2UKVNMVlaWqV+//tEY16xZY+rV\nq2f27NljjDFm4MCB5pZbbjGHDx82xhizbds289lnnxX6WqeddprZvn17mcXeu3dvM3LkSGOMMbff\nfrt57bXXTtgmJyfH7NixwxhjzPz5802zZs1Mdnb2CdvFxcUV+joF/Y6AWaaUn7uV42S2MfD++7b8\n94QJ8OyzWsRPqTBV3vNRtGzZkpSUFFJSUhgwYMBJxT5s2DCef/550tLS2LlzJ3379gXslUy33XYb\nYC/hPffcc2natCn9+vVjxIgRR89rOCXs5qNIT3ebFStyS/ak22+Ht9+2VzW9+y6kpwcnOKUqAZ2P\nIvSV9XwUFfccRW6uLcERHW1HWJ9xBvTrp/WZlFKqhCpmoli0CPr2hbPOgueftwX9CpkIXSmldD6K\nosaAtJMAAAjCSURBVFWsRHHkCAwbBkOGQGIi+C6fU0qVLWOM8xOIlaGKNB9FME4nVJxEsWABXH+9\n/dmnD7z8MtSo4XRUSlU40dHR7Ny5k2rVqlWoZFERGGPYuXMn0WU8HXPFSRSRkXDwoK3V1KuX09Eo\nVWGlpKSwYcMGtm/f7nQoqgDR0dGkpKSU6T7DO1FMmQJffQX/+Y8t4rdsGbjdTkelVIUWERFBamqq\n02GochTUS4BEpIeILBORDBEZXMB6EZGXfev/FJE2Ae143z47b3XXrjBu3LEifpoklFKqzAUtUYiI\nG3gN6Ak0Ba4Vkab5NusJpPtu/YA3ittv5CEDzZrZcREDBthzEtWrl3H0Siml8gSzRdEeyDDGrDLG\nHAFGAZfl2+Yy4EPfCPM/gGQRKbIsYvQWA0lJtojff/4DsbHBiV4ppRQQ3HMUdYH1fo83AB0C2KYu\nsNl/IxHph21xAByWRYsWaqVXAKoDZTf9VnjTY3GMHotj9Fgc06i0TwyLk9nGmLeBtwFEZFZph6FX\nNHosjtFjcYwei2P0WBwjIrNK+9xgdj1tBE71e5ziW1bSbZRSSjkomIliJpAuIqkiEgn0Ab7Kt81X\nwE2+q586AnuNMZvz70gppZRzgtb1ZIzJEZF7gImAG3jfGLNIRO7wrX8TGA9cBGQAB4FbA9j120EK\nORzpsThGj8UxeiyO0WNxTKmPRdiVGVdKKVW+tOa2UkqpImmiUEopVaSQTRRBK/8RhgI4Ftf7jsEC\nEZkmIq2ciLM8FHcs/LZrJyI5ItK7POMrT4EcCxHpKiLzRGSRiEwp7xjLSwD/I0ki8rWIzPcdi0DO\nh4YdEXlfRLaJyMJC1pfuc7O0k20H84Y9+b0SaABEAvOBpvm2uQj4DhCgIzDd6bgdPBZnAVV893tW\n5mPht93P2Islejsdt4N/F8nAYqCe73FNp+N28Fg8Agzz3a8B7AIinY49CMeiM9AGWFjI+lJ9boZq\niyIo5T/CVLHHwhgzzRiz2/fwD+x4lIookL8LgHuBz4Ft5RlcOQvkWFwHjDXGrAMwxlTU4xHIsTBA\ngtgJNOKxiSKnfMMMPmPML9j3VphSfW6GaqIorLRHSbf5//buNUTqKozj+PdXam43SaXIIteyvNW6\nlIWkUGY3i14UsouYZRRlF8rCkLAr9UKooEzMwmINvICWCSKShKYta7rmLbQyVEKKEpGKZX2h+/Ti\nnNFRZv/zn8lmZ2afD8yLOfP/z3nmsPt/5pyZeU41KPR1Pkp4x1CN8o6FpMuA+0lRYLLCpfm7uAa4\nSNJ6SVslPVSy6EorzVjMBYYBvwG7gOfMrKM04ZWVoq6bFVHCw6UjaRwhUYzt6li60HvATDPr8N3X\n6AHcAIwHaoAWSZvM7OeuDatL3AVsB24DrgLWStpoZn93bViVoVwThZf/OCnV65RUBywAJpjZ4RLF\nVmppxmIUsDQmif7APZKOmdmXpQmxZNKMxUHgsJm1AW2SNgAjgWpLFGnG4hFgtoWF+l8k7QeGAptL\nE2LZKOq6Wa5LT17+46S8YyHpCuALYEqVv1vMOxZmNsjMas2sFlgOPFWFSQLS/Y+sBMZK6iHpXEL1\n5j0ljrMU0ozFr4SZFZIuIVRS3VfSKMtDUdfNspxR2P9X/qPipByLV4F+wLz4TvqYVWHFzJRj0S2k\nGQsz2yNpDbAT6AAWmFnOr01WspR/F28CTZJ2Eb7xM9PMqq78uKQlwK1Af0kHgdeAnvDfrptewsM5\n51yicl16cs45VyY8UTjnnEvkicI551wiTxTOOecSeaJwzjmXyBOFKzuSjseKp5lbbcKxtZ1Vyiyw\nz/Wx+ugOSc2ShhTxHNMyZTIkTZU0IOuxBZKGn+E4t0iqT3HO9Pg7CueK4onClaN2M6vPuh0oUb+T\nzWwksBB4u9CT428XPot3pwIDsh57zMx2n5EoT8Y5j3RxTgc8UbiieaJwFSHOHDZK+j7ebs5xzAhJ\nm+MsZKekq2P7g1ntH0k6O093G4DB8dzxkrYp7PXxqaRzYvtsSbtjP+/EttclzVDYA2MUsCj2WRNn\nAqPirOPExT3OPOYWGWcLWQXdJH0oqVVhv4U3YtuzhIS1TtK62HanpJY4jssknZ+nH9fNeaJw5agm\na9lpRWz7E7jDzK4HGoE5Oc6bBrxvZvWEC/VBScPi8WNi+3Fgcp7+7wN2SeoNNAGNZnYdoZLBk5L6\nESrUjjCzOuCt7JPNbDnQSnjnX29m7VkPfx7PzWgk1KYqJs67gezyJLPiL/LrgFsk1ZnZHELF1HFm\nNk5Sf+Bl4PY4lq3AC3n6cd1cWZbwcN1ee7xYZusJzI1r8scJJbRP1wLMknQ5YR+GvZLGEyqobonl\nTWrofJ+KRZLagQOEPS2GAPuz6mctBJ4mlKw+CnwiaRWwKu0LM7NDkvbFOjt7CYXpmuPzFhJnL8K+\nCtnj1CDpccL/9aXAcEL5jmyjY3tz7KcXYdyc65QnClcpngf+IFQ/PYtwoT6FmS2W9B1wL7Ba0hOE\nuj4LzeylFH1MNrPWzB1JfXMdFGsL3UQoMjcReIZQvjqtpUAD8COwwsxM4aqdOk5gK+HziQ+AByQN\nAmYAN5rZEUlNQO8c5wpYa2aTCojXdXO+9OQqRR/g97jZzBRC8bdTSLoS2BeXW1YSlmC+BiZKujge\n01fSwJR9/gTUShoc708Bvolr+n3MbDUhgeXao/wf4IJOnncFYaexSYSkQaFxxnLZrwCjJQ0FLgTa\ngL8UqqNO6CSWTcCYzGuSdJ6kXLMz507wROEqxTzgYUk7CMs1bTmOaQB+kLQduJaw5eNuwpr8V5J2\nAmsJyzJ5mdlRQnXNZbHqaAcwn3DRXRWf71tyr/E3AfMzH2af9rxHCOW+B5rZ5thWcJzxs493gRfN\nbAewjTBLWUxYzsr4GFgjaZ2ZHSJ8I2tJ7KeFMJ7OdcqrxzrnnEvkMwrnnHOJPFE455xL5InCOedc\nIk8UzjnnEnmicM45l8gThXPOuUSeKJxzziX6FxN3uad/cn9RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d6e243f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs = u.predict_proba(X_train)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_train, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "pforest = clf.predict_proba(X_train)\n",
    "pforest1 = pforest[:,1]\n",
    "fpr1, tpr1, threshold1 = metrics.roc_curve(y_train, pforest1)\n",
    "roc_auc1 = metrics.auc(fpr1, tpr1)\n",
    "\n",
    "plog = logit.predict_proba(X_train)\n",
    "plog1 = plog[:,1]\n",
    "fpr2, tpr2, threshold2 = metrics.roc_curve(y_train, plog1)\n",
    "roc_auc2 = metrics.auc(fpr2, tpr2)\n",
    "\n",
    "# method I: plt\n",
    "#import matplotlib.pyplot as plt\n",
    "pyplot.title('Receiver Operating Characteristic')\n",
    "pyplot.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "pyplot.plot(fpr1, tpr1, 'g', label = 'AUC_f = %0.2f' % roc_auc1)\n",
    "pyplot.plot(fpr2, tpr2, 'y', label = 'AUC_L = %0.2f' % roc_auc2)\n",
    "pyplot.legend(loc = 'lower right')\n",
    "pyplot.plot([0, 1], [0, 1],'r--')\n",
    "pyplot.xlim([0, 1])\n",
    "pyplot.ylim([0, 1])\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Data (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Toy Data Random Forest data\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                            n_informative=2, n_redundant=0,\n",
    "                            random_state=0, shuffle=False)\n",
    "X_train = scaler.fit(X).transform(X)\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09424372  0.83597175  0.03343739  0.03634714]\n",
      "[ 0.92079208  0.97029703  0.99009901  0.97029703  0.95        0.95\n",
      "  0.92929293  0.92929293  0.93939394  0.8989899 ] 0.944845484548\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=100,max_features='sqrt', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "print(cross_val_score(clf, X_train, y_train, cv=10 ),\n",
    "np.abs(cross_val_score(clf, X_train, y_train, cv=10 ).mean()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [[ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[-0.57643759, -0.6723759 , -0.23639363,  0.54680607]]) , \n",
    "      clf.predict_proba([[-0.57643759, -0.6723759 , -0.23639363,  0.54680607]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff:  [[-0.48062427  4.20389638  0.09518497 -0.25831008]]\n",
      "Acc:  [ 0.93069307  0.94059406  0.95049505  0.97029703  0.95        0.96\n",
      "  0.95959596  0.92929293  0.93939394  0.92929293] 0.94596549655\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(fit_intercept=True)\n",
    "\n",
    "# Fit model. Let X_train = matrix of predictors, y_train = matrix of variable.\n",
    "# NOTE: Do not include a column for the intercept when fitting the model.\n",
    "resLogit = logit.fit(X_train, y_train)\n",
    "print('Coeff: ',resLogit.coef_)\n",
    "print('Acc: ',cross_val_score(resLogit, X_train, y_train, cv=10 )\n",
    "      , np.abs(cross_val_score(resLogit, X_train, y_train, cv=10 ).mean()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Sklearn vs Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors:  [ 0.14894159  0.15649742  0.29668446  0.14120487  0.14041639]\n",
      "Coefficients:     [ 0.32993529 -0.57036084  4.54675544  0.1001741  -0.28019433]\n"
     ]
    }
   ],
   "source": [
    "# Initiate logistic regression object\n",
    "logit = LogisticRegression(C=1e9,fit_intercept=True)\n",
    "\n",
    "# Fit model. Let X_train = matrix of predictors, y_train = matrix of variable.\n",
    "# NOTE: Do not include a column for the intercept when fitting the model.\n",
    "resLogit = logit.fit(X_train, y_train)\n",
    "#print(resLogit.intercept_,resLogit.coef_)\n",
    "\n",
    "# Calculate matrix of predicted class probabilities. \n",
    "# Check resLogit.classes_ to make sure that sklearn ordered your classes as expected\n",
    "predProbs = np.matrix(resLogit.predict_proba(X_train))\n",
    "\n",
    "# Design matrix -- add column of 1's at the beginning of your X_train matrix\n",
    "X_design = np.column_stack((np.ones(shape = X_train.shape[0]), X_train))\n",
    "#np.ones(shape = X_train.shape[0])\n",
    "#X_design =X_train\n",
    "\n",
    "# Initiate matrix of 0's, fill diagonal with each predicted observation's variance\n",
    "V = np.matrix(np.zeros(shape = (X_design.shape[0], X_design.shape[0])))\n",
    "np.fill_diagonal(V, np.multiply(predProbs[:,0], predProbs[:,1]).A1)\n",
    "\n",
    "# Covariance matrix\n",
    "covLogit = np.linalg.inv(X_design.T * V * X_design)\n",
    "#print(\"Covariance matrix: \", covLogit)\n",
    "\n",
    "# Standard errors\n",
    "print(\"Standard errors: \", np.sqrt(np.diag(covLogit)) )\n",
    "\n",
    "# Wald statistic (coefficient / s.e.) ^ 2\n",
    "logitParams = np.insert(resLogit.coef_, 0, resLogit.intercept_)\n",
    "print(\"Coefficients:    \",logitParams)\n",
    "#print( \"Wald statistics: \", (logitParams / np.sqrt(np.diag(covLogit))) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Logistic Regression - statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.184428\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>   <td>  1000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>   995</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 15 Oct 2017</td> <th>  Pseudo R-squ.:     </th>   <td>0.7339</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>20:46:42</td>     <th>  Log-Likelihood:    </th>  <td> -184.43</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -693.12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>6.125e-219</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3300</td> <td>    0.149</td> <td>    2.215</td> <td> 0.027</td> <td>    0.038</td> <td>    0.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.5704</td> <td>    0.156</td> <td>   -3.645</td> <td> 0.000</td> <td>   -0.877</td> <td>   -0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    4.5468</td> <td>    0.297</td> <td>   15.325</td> <td> 0.000</td> <td>    3.965</td> <td>    5.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1002</td> <td>    0.141</td> <td>    0.710</td> <td> 0.478</td> <td>   -0.177</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.2802</td> <td>    0.140</td> <td>   -1.995</td> <td> 0.046</td> <td>   -0.555</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1000\n",
       "Model:                          Logit   Df Residuals:                      995\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Sun, 15 Oct 2017   Pseudo R-squ.:                  0.7339\n",
       "Time:                        20:46:42   Log-Likelihood:                -184.43\n",
       "converged:                       True   LL-Null:                       -693.12\n",
       "                                        LLR p-value:                6.125e-219\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3300      0.149      2.215      0.027       0.038       0.622\n",
       "x1            -0.5704      0.156     -3.645      0.000      -0.877      -0.264\n",
       "x2             4.5468      0.297     15.325      0.000       3.965       5.128\n",
       "x3             0.1002      0.141      0.710      0.478      -0.177       0.377\n",
       "x4            -0.2802      0.140     -1.995      0.046      -0.555      -0.005\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    " \n",
    "model = sm.Logit(y_train, X_design)\n",
    " \n",
    "result =model.fit() #model.fit(method='bfgs')\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors:  [ 0.14894159  0.15649742  0.29668446  0.14120487  0.14041639]\n",
      "[0.622, -0.264, 5.128, 0.377, -0.005]\n",
      "[0.33, -0.57, 4.547, 0.1, -0.28]\n",
      "[0.038, -0.877, 3.965, -0.177, -0.555]\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard errors: \", np.sqrt(np.diag(covLogit)) )\n",
    "logitParams = np.insert(resLogit.coef_, 0, resLogit.intercept_)\n",
    "print([round(float(c+(1.96*v)),3) for c,v in zip(logitParams,np.sqrt(np.diag(covLogit)))])\n",
    "print([round(float(x),3) for x in logitParams])\n",
    "print([round(float(c-(1.96*v)),3) for c,v in zip(logitParams,np.sqrt(np.diag(covLogit)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.038, -0.877, 3.965, -0.177, -0.555]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(float(c+1.96*v),3) for c,v in zip(logitParams,np.sqrt(np.diag(covLogit)))]\n",
    "[round(float(c-1.96*v),3) for c,v in zip(logitParams,np.sqrt(np.diag(covLogit)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.27953753, -1.07614812,  0.34409454, -0.61389564],\n",
       "       [-2.26261269, -0.89834916,  0.78188638,  0.43062548],\n",
       "       [-0.47128857, -1.13624301, -3.07536742,  0.65616331],\n",
       "       ..., \n",
       "       [ 0.66923396,  0.95782361,  0.94200115, -2.29563862],\n",
       "       [ 0.05359401,  1.25619157, -0.38007636, -0.68146826],\n",
       "       [ 0.76300106,  0.00566496,  0.22060183, -1.97436012]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression Bayesian Inference approach :\n",
    "    - Pymc3 with Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -212.05, ||grad|| = 0.02526: 100%|█████████████████████████████████████████████| 15/15 [00:00<00:00, 161.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': array(0.3299516403912339), 'beta2': array(0.10019578934956035), 'beta0': array(-0.5703753341549249), 'beta1': array(4.546782324385807), 'beta3': array(-0.280172519081352)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -212.05, ||grad|| = 0.02526: 100%|█████████████████████████████████████████████| 15/15 [00:00<00:00, 141.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:45<00:00, 32.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 783.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 2617.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1 Use theano shared variable so that we can make predictions for new values later\n",
    "log_dose_shared0 = shared(X_train[:, 0])\n",
    "log_dose_shared1 = shared(X_train[:, 1])\n",
    "log_dose_shared2 = shared(X_train[:, 2])\n",
    "log_dose_shared3 = shared(X_train[:, 3])\n",
    "\n",
    "# Sample size in each group. The sample size has to be a shared variable too\n",
    "# Each row/observation is a group so n = total in group. 1 if only one per group\n",
    "n_shared = shared(np.ones(len(X_train), dtype=int))\n",
    "\n",
    "# Outcomes/Target\n",
    "deaths = y_train\n",
    "\n",
    "\n",
    "# 2 Build Probabilistic Model\n",
    "with Model() as bioassay_model:\n",
    "\n",
    "    # Priors for unknown model parameters. e.g. Logit-linear model parameters\n",
    "    alpha = Normal('alpha', 0, sd=100)\n",
    "    beta0 = Normal('beta0', 0, sd=100)\n",
    "    beta1 = Normal('beta1', 0, sd=100)\n",
    "    beta2 = Normal('beta2', 0, sd=100)\n",
    "    beta3 = Normal('beta3', 0, sd=100)\n",
    "    \n",
    "    # Expected value of outcome. e.g. link function outcome. Calculate probabilities of Y/Target\n",
    "    theta = invlogit(alpha + beta0 * log_dose_shared0 + beta1 * log_dose_shared1\\\n",
    "                     + beta2 * log_dose_shared2 + beta3 * log_dose_shared3 )\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations Data likelihood YTarget\n",
    "    obs_deaths = Binomial('obs_deaths', n=n_shared, p=theta, observed=deaths)\n",
    "\n",
    "    \n",
    "# 3 Finds the local maximum a posteriori point given a model. uses BFGS.\n",
    "from pymc3 import find_MAP\n",
    "# Runs fit to data returns parameters/coefficients\n",
    "map_estimate = find_MAP(model=bioassay_model)\n",
    "print(map_estimate)\n",
    "\n",
    "\n",
    "# 4 Now draw samples from the posterior using the given step methods.\n",
    "with bioassay_model:\n",
    "    \n",
    "    # obtain starting values via MAP\n",
    "    start = find_MAP(model=bioassay_model)\n",
    "    \n",
    "    # instantiate sampler\n",
    "    step = pm.Metropolis()\n",
    "    \n",
    "    # posterior of X's\n",
    "    # draw 1,000 posterior samples of independent variables\n",
    "    bioassay_trace = sample(1000, step=step, start=start)\n",
    "\n",
    "\n",
    "# 5 Generate posterior predictive samples from a model given a trace.\n",
    "from pymc3 import sample_ppc\n",
    "\n",
    "with bioassay_model:\n",
    "    deaths_sim = sample_ppc(bioassay_trace, samples=1000)\n",
    "    \n",
    "# take only last half  of posterior distr. of X's. other half was burn in.\n",
    "tr1 = bioassay_trace[500:]\n",
    "    \n",
    "#PREDICT\n",
    "log_dose_to_predict0 = X_train[:1000,0] #np.random.uniform(-0.8,0.7,size=50)\n",
    "log_dose_to_predict1 = X_train[:1000,1] #np.random.uniform(-0.8,0.7,size=50)\n",
    "log_dose_to_predict2 = X_train[:1000,2] #np.random.uniform(-0.8,0.7,size=50)\n",
    "log_dose_to_predict3 = X_train[:1000,3] #np.random.uniform(-0.8,0.7,size=50)\n",
    "n_predict = n = np.ones(1000, dtype=int)\n",
    "\n",
    "# Changing values here will also change values in the model\n",
    "log_dose_shared0.set_value(log_dose_to_predict0)\n",
    "log_dose_shared1.set_value(log_dose_to_predict1)\n",
    "log_dose_shared2.set_value(log_dose_to_predict2)\n",
    "log_dose_shared3.set_value(log_dose_to_predict3)\n",
    "n_shared.set_value(n_predict)\n",
    "\n",
    "# Simply running PPC will use the updated values and do prediction\n",
    "ppc = pm.sample_ppc(tr1, model=bioassay_model, samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.902246\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy:',(ppc['obs_deaths']==y[:1000]).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.57643759, -0.6723759 , -0.23639363,  0.54680607],\n",
       "        [-0.98566996,  1.12344181, -0.35003196, -1.1158904 ]]), array([0, 1]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[249:251],y_train[249:251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3965.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Changing values here will also change values in the model\n",
    "log_dose_shared0.set_value(np.array([-0.57643759]))\n",
    "log_dose_shared1.set_value(np.array([-0.6723759]))\n",
    "log_dose_shared2.set_value(np.array([-0.23639363]))\n",
    "log_dose_shared3.set_value(np.array([0.54680607]))\n",
    "n_shared.set_value(np.array([1]))\n",
    "\n",
    "# Simply running PPC will use the updated values and do prediction\n",
    "ppc = pm.sample_ppc(tr1, model=bioassay_model, samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.073999999999999996"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppc['obs_deaths'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3934.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Changing values here will also change values in the model\n",
    "log_dose_shared0.set_value(np.array([-0.98566996]))\n",
    "log_dose_shared1.set_value(np.array([1.12344181]))\n",
    "log_dose_shared2.set_value(np.array([-0.35003196]))\n",
    "log_dose_shared3.set_value(np.array([-1.1158904]))\n",
    "n_shared.set_value(np.array([1]))\n",
    "\n",
    "# Simply running PPC will use the updated values and do prediction\n",
    "ppc = pm.sample_ppc(tr1, model=bioassay_model, samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppc['obs_deaths'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': array(0.3299516403912339),\n",
       " 'beta0': array(-0.5703753341549249),\n",
       " 'beta1': array(4.546782324385807),\n",
       " 'beta2': array(0.10019578934956035),\n",
       " 'beta3': array(-0.280172519081352)}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logitInv= lambda x: np.exp(x)/(1.0+np.exp(x)) #sigmoid --> returns probability\n",
    "logitInv(map_estimate['alpha']+map_estimate['beta0']*X_train[249:251][1][0]+\\\n",
    "         map_estimate['beta1']*X_train[249:251][1][1]\\\n",
    "+map_estimate['beta2']*X_train[249:251][1][2]+map_estimate['beta3']*X_train[249:251][1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random, math\n",
    "\n",
    "# def k_fold(data, myseed=11109, k=10):\n",
    "#     # Load data\n",
    "#     #data = open(myfile).readlines()\n",
    "\n",
    "#     # Shuffle input\n",
    "#     random.seed=myseed\n",
    "#     random.shuffle(data)\n",
    "\n",
    "#     # Compute partition size given input k\n",
    "#     len_part=int(math.ceil(len(data)/float(k)))\n",
    "\n",
    "#     # Create one partition per fold\n",
    "#     train={}\n",
    "#     test={}\n",
    "#     for ii in range(k):\n",
    "#         test[ii]  = data[ii*len_part:ii*len_part+len_part]\n",
    "#         train[ii] = [jj for jj in data if jj not in test[ii]]\n",
    "\n",
    "#     return train, test \n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.errorbar(x=log_dose_to_predict0[:50], y=np.asarray(ppc['obs_deaths']).mean(axis=0)[:50], yerr=np.asarray(ppc['obs_deaths']).std(axis=0)[:50], linestyle='', marker='o')\n",
    "# plt.plot(X_train[:50, 1], deaths[:50], 'o')\n",
    "# plt.xlabel('log_dose',size=15)s\n",
    "# plt.ylabel('number of rats with tumors',size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(n_estimators = 100, max_features='sqrt')\n",
    "# rf.fit(X, y)\n",
    "# # feature importances\n",
    "# # the higher, the more important the feature\n",
    "# d = {'importance': rf.feature_importances_}\n",
    "# pd.DataFrame(d, index=X.columns).sort('importance')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
